{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System:\n",
      "    python: 3.8.5 (tags/v3.8.5:580fbb0, Jul 20 2020, 15:57:54) [MSC v.1924 64 bit (AMD64)]\n",
      "executable: c:\\users\\alexa\\appdata\\local\\programs\\python\\python38\\python.exe\n",
      "   machine: Windows-10-10.0.19041-SP0\n",
      "\n",
      "Python dependencies:\n",
      "          pip: 21.3.1\n",
      "   setuptools: 47.1.0\n",
      "      sklearn: 0.24.1\n",
      "        numpy: 1.19.2\n",
      "        scipy: 1.5.2\n",
      "       Cython: 0.29.22\n",
      "       pandas: 1.1.3\n",
      "   matplotlib: 3.3.2\n",
      "       joblib: 0.17.0\n",
      "threadpoolctl: 2.1.0\n",
      "\n",
      "Built with OpenMP: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "sklearn.show_versions()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = 'online_shoppers_intentions'\n",
    "\n",
    "df1r0 = pd.read_csv(\"../data/train/noresampling/\"+filename1+\"_0.csv\", index_col=0)\n",
    "df1u0 = pd.read_csv(\"../data/train/undersampled/\"+filename1+\"_0.csv\", index_col=0)\n",
    "df1o0 = pd.read_csv(\"../data/train/oversampled/\"+filename1+\"_0.csv\", index_col=0)\n",
    "\n",
    "df1r10 = pd.read_csv(\"../data/train/noresampling/\"+filename1+\"_10.csv\", index_col=0)\n",
    "df1u10 = pd.read_csv(\"../data/train/undersampled/\"+filename1+\"_10.csv\", index_col=0)\n",
    "df1o10 = pd.read_csv(\"../data/train/oversampled/\"+filename1+\"_10.csv\", index_col=0)\n",
    "\n",
    "df1r20 = pd.read_csv(\"../data/train/noresampling/\"+filename1+\"_20.csv\", index_col=0)\n",
    "df1u20 = pd.read_csv(\"../data/train/undersampled/\"+filename1+\"_20.csv\", index_col=0)\n",
    "df1o20 = pd.read_csv(\"../data/train/oversampled/\"+filename1+\"_20.csv\", index_col=0)\n",
    "\n",
    "df1r50 = pd.read_csv(\"../data/train/noresampling/\"+filename1+\"_50.csv\", index_col=0)\n",
    "df1u50 = pd.read_csv(\"../data/train/undersampled/\"+filename1+\"_50.csv\", index_col=0)\n",
    "df1o50 = pd.read_csv(\"../data/train/oversampled/\"+filename1+\"_50.csv\", index_col=0)\n",
    "\n",
    "df1r90 = pd.read_csv(\"../data/train/noresampling/\"+filename1+\"_90.csv\", index_col=0)\n",
    "df1u90 = pd.read_csv(\"../data/train/undersampled/\"+filename1+\"_90.csv\", index_col=0)\n",
    "df1o90 = pd.read_csv(\"../data/train/oversampled/\"+filename1+\"_90.csv\", index_col=0)\n",
    "\n",
    "df1r95 = pd.read_csv(\"../data/train/noresampling/\"+filename1+\"_95.csv\", index_col=0)\n",
    "df1u95 = pd.read_csv(\"../data/train/undersampled/\"+filename1+\"_95.csv\", index_col=0)\n",
    "df1o95 = pd.read_csv(\"../data/train/oversampled/\"+filename1+\"_95.csv\", index_col=0)\n",
    "\n",
    "df1t = pd.read_csv(\"../data/test/\"+filename1+\".csv\", index_col=0)\n",
    "\n",
    "numerical_features1 = [\"Administrative\", \"Administrative_Duration\", \"Informational\", \"Informational_Duration\", \n",
    "                      \"ProductRelated\", \"ProductRelated_Duration\", \"BounceRates\", \"ExitRates\", \"PageValues\", \"SpecialDay\"]\n",
    "categorical_features1 = [\"OperatingSystems\", \"Browser\", \"Region\", \"TrafficType\", \"VisitorType\", \"Weekend\", \"Month\"]\n",
    "target1 = 'Revenue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2 = 'marketing_campaign'\n",
    "\n",
    "df2r0 = pd.read_csv(\"../data/train/noresampling/\"+filename2+\"_0.csv\", index_col=0)\n",
    "df2u0 = pd.read_csv(\"../data/train/undersampled/\"+filename2+\"_0.csv\", index_col=0)\n",
    "df2o0 = pd.read_csv(\"../data/train/oversampled/\"+filename2+\"_0.csv\", index_col=0)\n",
    "\n",
    "df2r10 = pd.read_csv(\"../data/train/noresampling/\"+filename2+\"_10.csv\", index_col=0)\n",
    "df2u10 = pd.read_csv(\"../data/train/undersampled/\"+filename2+\"_10.csv\", index_col=0)\n",
    "df2o10 = pd.read_csv(\"../data/train/oversampled/\"+filename2+\"_10.csv\", index_col=0)\n",
    "\n",
    "df2r20 = pd.read_csv(\"../data/train/noresampling/\"+filename2+\"_20.csv\", index_col=0)\n",
    "df2u20 = pd.read_csv(\"../data/train/undersampled/\"+filename2+\"_20.csv\", index_col=0)\n",
    "df2o20 = pd.read_csv(\"../data/train/oversampled/\"+filename2+\"_20.csv\", index_col=0)\n",
    "\n",
    "df2r50 = pd.read_csv(\"../data/train/noresampling/\"+filename2+\"_50.csv\", index_col=0)\n",
    "df2u50 = pd.read_csv(\"../data/train/undersampled/\"+filename2+\"_50.csv\", index_col=0)\n",
    "df2o50 = pd.read_csv(\"../data/train/oversampled/\"+filename2+\"_50.csv\", index_col=0)\n",
    "\n",
    "df2r90 = pd.read_csv(\"../data/train/noresampling/\"+filename2+\"_90.csv\", index_col=0)\n",
    "df2u90 = pd.read_csv(\"../data/train/undersampled/\"+filename2+\"_90.csv\", index_col=0)\n",
    "df2o90 = pd.read_csv(\"../data/train/oversampled/\"+filename2+\"_90.csv\", index_col=0)\n",
    "\n",
    "df2r95 = pd.read_csv(\"../data/train/noresampling/\"+filename2+\"_95.csv\", index_col=0)\n",
    "df2u95 = pd.read_csv(\"../data/train/undersampled/\"+filename2+\"_95.csv\", index_col=0)\n",
    "df2o95 = pd.read_csv(\"../data/train/oversampled/\"+filename2+\"_95.csv\", index_col=0)\n",
    "\n",
    "df2t = pd.read_csv(\"../data/test/\"+filename2+\".csv\", index_col=0)\n",
    "\n",
    "numerical_features2 = ['Income','MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts','MntSweetProducts', \n",
    "                        'MntGoldProds','Year_Birth','Recency','NumDealsPurchases','NumWebPurchases',\n",
    "                        'NumCatalogPurchases','NumStorePurchases','NumWebVisitsMonth','Dt_Customer']\n",
    "categorical_features2 = ['Education','Marital_Status','Kidhome','AcceptedCmp3', \n",
    "                        'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2','Complain','Response']\n",
    "target2 = 'Teenhome'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename3 = 'heart'\n",
    "\n",
    "df3r0 = pd.read_csv(\"../data/train/noresampling/\"+filename3+\"_0.csv\", index_col=0)\n",
    "df3u0 = pd.read_csv(\"../data/train/undersampled/\"+filename3+\"_0.csv\", index_col=0)\n",
    "df3o0 = pd.read_csv(\"../data/train/oversampled/\"+filename3+\"_0.csv\", index_col=0)\n",
    "\n",
    "df3r10 = pd.read_csv(\"../data/train/noresampling/\"+filename3+\"_10.csv\", index_col=0)\n",
    "df3u10 = pd.read_csv(\"../data/train/undersampled/\"+filename3+\"_10.csv\", index_col=0)\n",
    "df3o10 = pd.read_csv(\"../data/train/oversampled/\"+filename3+\"_10.csv\", index_col=0)\n",
    "\n",
    "df3r20 = pd.read_csv(\"../data/train/noresampling/\"+filename3+\"_20.csv\", index_col=0)\n",
    "df3u20 = pd.read_csv(\"../data/train/undersampled/\"+filename3+\"_20.csv\", index_col=0)\n",
    "df3o20 = pd.read_csv(\"../data/train/oversampled/\"+filename3+\"_20.csv\", index_col=0)\n",
    "\n",
    "df3r50 = pd.read_csv(\"../data/train/noresampling/\"+filename3+\"_50.csv\", index_col=0)\n",
    "df3u50 = pd.read_csv(\"../data/train/undersampled/\"+filename3+\"_50.csv\", index_col=0)\n",
    "df3o50 = pd.read_csv(\"../data/train/oversampled/\"+filename3+\"_50.csv\", index_col=0)\n",
    "\n",
    "df3r90 = pd.read_csv(\"../data/train/noresampling/\"+filename3+\"_90.csv\", index_col=0)\n",
    "df3u90 = pd.read_csv(\"../data/train/undersampled/\"+filename3+\"_90.csv\", index_col=0)\n",
    "df3o90 = pd.read_csv(\"../data/train/oversampled/\"+filename3+\"_90.csv\", index_col=0)\n",
    "\n",
    "df3r95 = pd.read_csv(\"../data/train/noresampling/\"+filename3+\"_95.csv\", index_col=0)\n",
    "df3u95 = pd.read_csv(\"../data/train/undersampled/\"+filename3+\"_95.csv\", index_col=0)\n",
    "df3o95 = pd.read_csv(\"../data/train/oversampled/\"+filename3+\"_95.csv\", index_col=0)\n",
    "\n",
    "df3t = pd.read_csv(\"../data/test/\"+filename3+\".csv\", index_col=0)\n",
    "\n",
    "numerical_features3 = ['trestbps','chol','thalach','oldpeak', 'age']\n",
    "categorical_features3 = ['sex', 'cp','fbs','restecg','exang','slope','ca','thal']\n",
    "target3 = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 1514\n",
      "0.9499478623566214 8631\n",
      "0.2 14590\n",
      "0.8962264150943396 212\n",
      "0.09973579920739763 1514\n",
      "0.0 91\n"
     ]
    }
   ],
   "source": [
    "# SANITY CHECKS\n",
    "print(df2u50[target2].isnull().sum()/len(df2u50), len(df2u50))\n",
    "print(df1r95[target1].isnull().sum()/len(df1r95), len(df1r95))\n",
    "print(df1o20[target1].isnull().sum()/len(df1o20), len(df1o20))\n",
    "print(df3r90[target3].isnull().sum()/len(df3r90), len(df3r90))\n",
    "print(df2u10[target2].isnull().sum()/len(df2u10), len(df2u10))\n",
    "print(df3t[target3].isnull().sum()/len(df3t), len(df3t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Self_Train_1(dftrain, dftest, categorical_features, numerical_features, target, model):\n",
    "        \n",
    "    start_time = time.time()\n",
    "    \n",
    "    X_train = dftrain[numerical_features+categorical_features]\n",
    "    y_train = dftrain[target]\n",
    "    pseudo = y_train.fillna(-1)\n",
    "    \n",
    "    X_test = dftest[numerical_features+categorical_features]\n",
    "    y_test = dftest[target]\n",
    "    \n",
    "    X_train[categorical_features] = X_train[categorical_features].astype('category')\n",
    "    X_test[categorical_features] = X_test[categorical_features].astype('category')\n",
    "    \n",
    "    m = SelfTrainingClassifier(model)\n",
    "    m.fit(X_train, pseudo)\n",
    "    y_pred = m.predict(X_test)\n",
    "    \n",
    "    execution = time.time() - start_time\n",
    "    \n",
    "    return [execution, y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Self_Train_All(dftrains, dftest, categorical_features, numerical_features, target, model, sampling, filename):\n",
    "    \n",
    "    y_test = dftest[target]\n",
    "    \n",
    "    results0 = Self_Train_1(dftrains[0], dftest, categorical_features, numerical_features, target, model)\n",
    "    print('DONE: '+sampling+\"-\"+filename+'-0')\n",
    "    results10 = Self_Train_1(dftrains[1], dftest, categorical_features, numerical_features, target, model)\n",
    "    print('DONE: '+sampling+\"-\"+filename+'-10')\n",
    "    results20 = Self_Train_1(dftrains[2], dftest, categorical_features, numerical_features, target, model)\n",
    "    print('DONE: '+sampling+\"-\"+filename+'-20')\n",
    "    results50 = Self_Train_1(dftrains[3], dftest, categorical_features, numerical_features, target, model)\n",
    "    print('DONE: '+sampling+\"-\"+filename+'-50')\n",
    "    results90 = Self_Train_1(dftrains[4], dftest, categorical_features, numerical_features, target, model)\n",
    "    print('DONE: '+sampling+\"-\"+filename+'-90')\n",
    "    results95 = Self_Train_1(dftrains[5], dftest, categorical_features, numerical_features, target, model)\n",
    "    print('DONE: '+sampling+\"-\"+filename+'-95')\n",
    "    \n",
    "    executions = [results0[0],results10[0],results20[0],results50[0],results90[0],results95[0]] \n",
    "    unlabelled = ['0','10','20','50','90','95']\n",
    "    \n",
    "    predictions_data = {'y_true':y_test, 'y_0':results0[1], 'y_10':results10[1], 'y_20':results20[1], \n",
    "                        'y_50':results50[1], 'y_90':results90[1], 'y_95':results95[1]}\n",
    "    prediction_df = pd.DataFrame(predictions_data)\n",
    "    prediction_df.to_csv('../data/pred/selftraining/'+sampling+'/'+filename+'.csv')\n",
    "    \n",
    "    time_data = {'unlabelled':unlabelled,'time':executions}\n",
    "    time_df = pd.DataFrame(time_data)\n",
    "    time_df.to_csv('../data/pred/selftraining/'+sampling+'/'+filename+'_time.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: noresampling-online_shoppers_intentions-0\n",
      "DONE: noresampling-online_shoppers_intentions-10\n",
      "DONE: noresampling-online_shoppers_intentions-20\n",
      "DONE: noresampling-online_shoppers_intentions-50\n",
      "DONE: noresampling-online_shoppers_intentions-90\n",
      "DONE: noresampling-online_shoppers_intentions-95\n",
      "DONE: undersampled-online_shoppers_intentions-0\n",
      "DONE: undersampled-online_shoppers_intentions-10\n",
      "DONE: undersampled-online_shoppers_intentions-20\n",
      "DONE: undersampled-online_shoppers_intentions-50\n",
      "DONE: undersampled-online_shoppers_intentions-90\n",
      "DONE: undersampled-online_shoppers_intentions-95\n",
      "DONE: oversampled-online_shoppers_intentions-0\n",
      "DONE: oversampled-online_shoppers_intentions-10\n",
      "DONE: oversampled-online_shoppers_intentions-20\n",
      "DONE: oversampled-online_shoppers_intentions-50\n",
      "DONE: oversampled-online_shoppers_intentions-90\n",
      "DONE: oversampled-online_shoppers_intentions-95\n"
     ]
    }
   ],
   "source": [
    "# Best Supervised Model and Hyperparameters found in notebooks 1. and 2.\n",
    "\n",
    "# ONLINE SHOPPING INTENTION\n",
    "gbe_1 = GradientBoostingClassifier(learning_rate=1, max_depth=1, n_estimators=5) #no-resampling\n",
    "rf_1 = RandomForestClassifier(max_depth=5, max_features=3, min_samples_leaf=3, min_samples_split=8, n_estimators=100)\n",
    "\n",
    "noresampling = [df1r0,df1r10,df1r20,df1r50,df1r90,df1r95]\n",
    "undersampling = [df1u0,df1u10,df1u20,df1u50,df1u90,df1u95]\n",
    "oversampling = [df1o0,df1o10,df1o20,df1o50,df1o90,df1o95]\n",
    "\n",
    "Self_Train_All(noresampling, df1t, categorical_features1, numerical_features1, target1, gbe_1, 'noresampling', filename1)\n",
    "Self_Train_All(undersampling, df1t, categorical_features1, numerical_features1, target1, rf_1, 'undersampled', filename1)\n",
    "Self_Train_All(oversampling, df1t, categorical_features1, numerical_features1, target1, rf_1, 'oversampled', filename1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['trestbps', 'chol', 'thalach', 'oldpeak', 'age', 'sex', 'cp', 'fbs',\\n       'restecg', 'exang', 'slope', 'ca', 'thal'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-150-f6fa2688dc85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0moversampling\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdf2o0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf2o10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf2o20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf2o50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf2o90\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf2o95\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mSelf_Train_All\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoresampling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf3t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_features3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumerical_features3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgbe_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'noresampling'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mSelf_Train_All\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mundersampling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf3t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_features3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumerical_features3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'undersampled'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mSelf_Train_All\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moversampling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf3t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_features3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumerical_features3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'oversampled'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-146-5a3e28b66abb>\u001b[0m in \u001b[0;36mSelf_Train_All\u001b[1;34m(dftrains, dftest, categorical_features, numerical_features, target, model, sampling, filename)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdftest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mresults0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSelf_Train_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdftrains\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdftest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumerical_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DONE: '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msampling\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'-0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mresults10\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSelf_Train_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdftrains\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdftest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumerical_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-145-624c1db35274>\u001b[0m in \u001b[0;36mSelf_Train_1\u001b[1;34m(dftrain, dftest, categorical_features, numerical_features, target, model)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdftrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumerical_features\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcategorical_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdftrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mpseudo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2906\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2908\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2910\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1296\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1298\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m             \u001b[1;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['trestbps', 'chol', 'thalach', 'oldpeak', 'age', 'sex', 'cp', 'fbs',\\n       'restecg', 'exang', 'slope', 'ca', 'thal'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# MARKETING CAMPAIGN\n",
    "gbe_2 = GradientBoostingClassifier(learning_rate=0.1, max_depth=3, n_estimators=250) #no-resampling\n",
    "rf_2 = RandomForestClassifier(max_depth=15, max_features=5, min_samples_leaf=3, min_samples_split=8, n_estimators=200)\n",
    "\n",
    "noresampling = [df2r0,df2r10,df2r20,df2r50,df2r90,df2r95]\n",
    "undersampling = [df2u0,df2u10,df2u20,df2u50,df2u90,df2u95]\n",
    "oversampling = [df2o0,df2o10,df2o20,df2o50,df2o90,df2o95]\n",
    "\n",
    "Self_Train_All(noresampling, df2t, categorical_features2, numerical_features2, target2, gbe_2, 'noresampling', filename2)\n",
    "Self_Train_All(undersampling, df2t, categorical_features2, numerical_features2, target2, rf_2, 'undersampled', filename2)\n",
    "Self_Train_All(oversampling, df2t, categorical_features2, numerical_features2, target2, rf_2, 'oversampled', filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: noresampling-heart-0\n",
      "DONE: noresampling-heart-10\n",
      "DONE: noresampling-heart-20\n",
      "DONE: noresampling-heart-50\n",
      "DONE: noresampling-heart-90\n",
      "DONE: noresampling-heart-95\n",
      "DONE: undersampled-heart-0\n",
      "DONE: undersampled-heart-10\n",
      "DONE: undersampled-heart-20\n",
      "DONE: undersampled-heart-50\n",
      "DONE: undersampled-heart-90\n",
      "DONE: undersampled-heart-95\n",
      "DONE: oversampled-heart-0\n",
      "DONE: oversampled-heart-10\n",
      "DONE: oversampled-heart-20\n",
      "DONE: oversampled-heart-50\n",
      "DONE: oversampled-heart-90\n",
      "DONE: oversampled-heart-95\n"
     ]
    }
   ],
   "source": [
    "# HEART\n",
    "dt_3 = DecisionTreeClassifier(criterion='entropy', max_depth=2, min_samples_leaf=1, min_samples_split= 2) #no-resampling\n",
    "gbe_3 = GradientBoostingClassifier(learning_rate=1, max_depth=1, n_estimators=50)\n",
    "\n",
    "noresampling = [df3r0,df3r10,df3r20,df3r50,df3r90,df3r95]\n",
    "undersampling = [df3u0,df3u10,df3u20,df3u50,df3u90,df3u95]\n",
    "oversampling = [df3o0,df3o10,df3o20,df3o50,df3o90,df3o95]\n",
    "\n",
    "Self_Train_All(noresampling, df3t, categorical_features3, numerical_features3, target3, dt_3, 'noresampling', filename3)\n",
    "Self_Train_All(undersampling, df3t, categorical_features3, numerical_features3, target3, gbe_3, 'undersampled', filename3)\n",
    "Self_Train_All(oversampling, df3t, categorical_features3, numerical_features3, target3, gbe_3, 'oversampled', filename3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1]\n",
      "1    115\n",
      "0     97\n",
      "Name: target, dtype: int64\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[-1.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "-1.0    201\n",
      "1.0       6\n",
      "0.0       5\n",
      "Name: target, dtype: int64\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#Sanity checks\n",
    "\n",
    "results = Self_Train_1(df3r0, df3t, categorical_features3, numerical_features3, target3, dt_3)\n",
    "print(results[1])\n",
    "\n",
    "results = Self_Train_1(df3r95, df3t, categorical_features3, numerical_features3, target3, dt_3)\n",
    "print(results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
