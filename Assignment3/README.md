# Assignment 3

Student Name: Alexandra Sklokin

Student Number: 300010511

This is my Assignment 3 submission.

## Data

Contains original data, possible processed datasets, and the optimal dataset for Decision Tree Classifier based on F1-Score).

## Results

Contains various visualizations of Decision Tree Model, the model itself, confusion matrix, Excel sheet with test data and predictions, and example of Decision Tree path.

## Preprocessing

Notebook to creating the possible processed datasets, and selecting an optimal dataset.

## ParameterTuning

Notebook for parameter tuning of the Decision Tree Classifier, using the optimal dataset.

## Training

Notebook for Decision Tree Classifier training, which produces items found in 'Results' folder.

## Report

Contains files used to create the report (done in Overleaf), and the report itself.

## References

Elaine Angelino et al. Learning Certifiably Optimal Rule Lists for Categorical Data. 2018. arXiv: 1704.01701 [stat.ML].

Chaofan Chen et al. This Looks Like That: Deep Learning for Interpretable Image Recognition. 2019. arXiv: 1806.10574 [cs.LG].

Tim Miller. Explanation in Artificial Intelligence: Insights from the Social Sciences. 2018. arXiv: 1706.07269 [cs.AI].

Cynthia Rudin and Joanna Radin. “Why Are We Using Black Box Models in AI When We Don’t Need To? A Lesson From An Explainable AI Competition”. In: Harvard Data Science Review 1.2 (Nov. 22, 2019). doi: 10.1162/99608f92.5a8a3a3d. url: https://hdsr.mitpress.mit.edu/ pub/f9kuryi8.

Farhad Shakerin and Gopal Gupta. White-box Induction From SVM Models: Explainable AI with Logic Programming. 2020. arXiv: 2008 . 03301 [cs.AI].

Herna Viktor. Topic4 Trees (CSI5155 Lecture Notes). Nov. 2021.

