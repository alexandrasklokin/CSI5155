{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from numpy import asarray\n",
    "from statistics import mean\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import set_printoptions\n",
    "from statistics import mean\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier, LabelPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.SemiBoost import SemiBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLINE SHOPPING INTENTIONS\n",
    "\n",
    "filename1 = 'online_shoppers_intentions'\n",
    "df1r0 = pd.read_csv(\"../data/train/noresampling/\"+filename1+\"_0.csv\", index_col=0)\n",
    "df1t = pd.read_csv(\"../data/test/\"+filename1+\".csv\", index_col=0)\n",
    "target1 = 'Revenue'\n",
    "\n",
    "numerical_features1 = [\"Administrative\", \"Administrative_Duration\", \"Informational\", \"Informational_Duration\", \n",
    "                      \"ProductRelated\", \"ProductRelated_Duration\", \"BounceRates\", \"ExitRates\", \"PageValues\", \"SpecialDay\"]\n",
    "categorical_features1 = [\"OperatingSystems\", \"Browser\", \"Region\", \"TrafficType\", \"VisitorType\", \"Weekend\", \"Month\"]\n",
    "df1r0[categorical_features1] = df1r0[categorical_features1].astype('category')  \n",
    "df1t[categorical_features1] = df1t[categorical_features1].astype('category')\n",
    "df1r0[target1] = df1r0[target1].astype('category') \n",
    "df1t[target1] = df1t[target1].astype('category')\n",
    "\n",
    "\n",
    "# MARKETING CAMPAIGN\n",
    "\n",
    "filename2 = 'marketing_campaign'\n",
    "df2r0 = pd.read_csv(\"../data/train/noresampling/\"+filename2+\"_0.csv\", index_col=0)\n",
    "df2t = pd.read_csv(\"../data/test/\"+filename2+\".csv\", index_col=0)\n",
    "target2 = 'Teenhome'\n",
    "\n",
    "numerical_features2 = ['Income','MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts','MntSweetProducts', \n",
    "                        'MntGoldProds','Year_Birth','Recency','NumDealsPurchases','NumWebPurchases',\n",
    "                        'NumCatalogPurchases','NumStorePurchases','NumWebVisitsMonth','Dt_Customer']\n",
    "categorical_features2 = ['Education','Marital_Status','Kidhome','AcceptedCmp3', \n",
    "                        'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2','Complain','Response']\n",
    "df2r0[categorical_features2] = df2r0[categorical_features2].astype('category') \n",
    "df2t[categorical_features2] = df2t[categorical_features2].astype('category')\n",
    "df2r0[target2] = df2r0[target2].astype('category') \n",
    "df2t[target2] = df2t[target2].astype('category')\n",
    "\n",
    "# HEART\n",
    "\n",
    "filename3 = 'heart'\n",
    "df3r0 = pd.read_csv(\"../data/train/noresampling/\"+filename3+\"_0.csv\", index_col=0)\n",
    "df3t = pd.read_csv(\"../data/test/\"+filename3+\".csv\", index_col=0)\n",
    "target3 = 'target'\n",
    "\n",
    "numerical_features3 = ['trestbps','chol','thalach','oldpeak', 'age']\n",
    "categorical_features3 = ['sex', 'cp','fbs','restecg','exang','slope','ca','thal']\n",
    "df3r0[categorical_features3] = df3r0[categorical_features3].astype('category') \n",
    "df3t[categorical_features3] = df3t[categorical_features3].astype('category') \n",
    "df3r0[target3] = df3r0[target3].astype('category') \n",
    "df3t[target3] = df3t[target3].astype('category')\n",
    "\n",
    "# Sanity Check\n",
    "#df1r0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ParameterTuning (dataset_name, dfr, dft, target, numerical_features, categorical_features, model, grid_params):\n",
    "    \n",
    "    print(\"_______________________________________________________________________________ Dataset:\"+dataset_name)\n",
    "\n",
    "    Xr_train = dfr[numerical_features+categorical_features]\n",
    "    yr_train = dfr[target]\n",
    "    \n",
    "    X_test = dft[numerical_features+categorical_features]\n",
    "    y_test = dft[target]\n",
    "\n",
    "    mod = GridSearchCV(model, grid_params, verbose=1, cv=3, n_jobs=-1)\n",
    "    results_r = mod.fit(Xr_train, yr_train)\n",
    "    print(results_r.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________RF\n",
      "_______________________________________________________________________________ Dataset:heart\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
      "{'criterion': 'threshold', 'k_best': 10, 'max_iter': 10, 'threshold': 0.8}\n",
      "_______________________________________________________________________________ Dataset:marketing_campaign\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
      "{'criterion': 'threshold', 'k_best': 200, 'max_iter': 10, 'threshold': 0.8}\n",
      "_______________________________________________________________________________ Dataset:online_shoppers_intentions\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
      "{'criterion': 'threshold', 'k_best': 100, 'max_iter': 200, 'threshold': 0.9}\n",
      "__________________________________________________________________________________________________GBE\n",
      "_______________________________________________________________________________ Dataset:heart\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
      "{'criterion': 'threshold', 'k_best': 100, 'max_iter': 200, 'threshold': 0.25}\n",
      "_______________________________________________________________________________ Dataset:marketing_campaign\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
      "{'criterion': 'threshold', 'k_best': 10, 'max_iter': None, 'threshold': 0.8}\n",
      "_______________________________________________________________________________ Dataset:online_shoppers_intentions\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
      "{'criterion': 'threshold', 'k_best': 10, 'max_iter': 200, 'threshold': 0.5}\n",
      "__________________________________________________________________________________________________DT\n",
      "_______________________________________________________________________________ Dataset:heart\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
      "{'criterion': 'k_best', 'k_best': 10, 'max_iter': 100, 'threshold': 0.9}\n",
      "_______________________________________________________________________________ Dataset:marketing_campaign\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
      "{'criterion': 'k_best', 'k_best': 200, 'max_iter': 200, 'threshold': 0.25}\n",
      "_______________________________________________________________________________ Dataset:online_shoppers_intentions\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
      "{'criterion': 'threshold', 'k_best': 200, 'max_iter': None, 'threshold': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# SelfTraining\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "gbe_model = GradientBoostingClassifier()\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'threshold': [0.25, 0.50, 0.75, 0.80, 0.90],\n",
    "    'criterion': ['threshold', 'k_best'],\n",
    "    'k_best': [10,100,200],\n",
    "    'max_iter': [10,100,200,None]\n",
    "}\n",
    "print(\"__________________________________________________________________________________________________RF\")\n",
    "ParameterTuning (filename3, df3r0, df3t, target3, numerical_features3, categorical_features3, SelfTrainingClassifier(rf_model), param_grid)\n",
    "ParameterTuning (filename2, df2r0, df2t, target2, numerical_features2, categorical_features2, SelfTrainingClassifier(rf_model), param_grid)\n",
    "ParameterTuning (filename1, df1r0, df1t, target1, numerical_features1, categorical_features1, SelfTrainingClassifier(rf_model), param_grid)\n",
    "\n",
    "print(\"__________________________________________________________________________________________________GBE\")\n",
    "ParameterTuning (filename3, df3r0, df3t, target3, numerical_features3, categorical_features3, SelfTrainingClassifier(gbe_model), param_grid)\n",
    "ParameterTuning (filename2, df2r0, df2t, target2, numerical_features2, categorical_features2, SelfTrainingClassifier(gbe_model), param_grid)\n",
    "ParameterTuning (filename1, df1r0, df1t, target1, numerical_features1, categorical_features1, SelfTrainingClassifier(gbe_model), param_grid)\n",
    "\n",
    "print(\"__________________________________________________________________________________________________DT\")\n",
    "ParameterTuning (filename3, df3r0, df3t, target3, numerical_features3, categorical_features3, SelfTrainingClassifier(dt_model), param_grid)\n",
    "ParameterTuning (filename2, df2r0, df2t, target2, numerical_features2, categorical_features2, SelfTrainingClassifier(dt_model), param_grid)\n",
    "ParameterTuning (filename1, df1r0, df1t, target1, numerical_features1, categorical_features1, SelfTrainingClassifier(dt_model), param_grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________ Dataset:heart\n",
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n",
      "{'gamma': 40, 'kernel': 'rbf', 'max_iter': 10, 'n_neighbors': 3, 'tol': 0.0001}\n",
      "_______________________________________________________________________________ Dataset:marketing_campaign\n",
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n",
      "{'gamma': 20, 'kernel': 'knn', 'max_iter': 10, 'n_neighbors': 5, 'tol': 0.0001}\n",
      "_______________________________________________________________________________ Dataset:online_shoppers_intentions\n",
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n",
      "{'gamma': 20, 'kernel': 'knn', 'max_iter': 10, 'n_neighbors': 5, 'tol': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "# Label Propogation\n",
    "\n",
    "param_grid = {\n",
    "    'kernel': ['knn','rbf'],\n",
    "    'gamma': [20,40],\n",
    "    'n_neighbors': [3,5],\n",
    "    'max_iter': [10,100,200,None],\n",
    "    'tol':[0.0001, 0.001]\n",
    "}\n",
    "\n",
    "ParameterTuning (filename3, df3r0, df3t, target3, numerical_features3, categorical_features3, LabelPropagation(), param_grid)\n",
    "ParameterTuning (filename2, df2r0, df2t, target2, numerical_features2, categorical_features2, LabelPropagation(), param_grid)\n",
    "ParameterTuning (filename1, df1r0, df1t, target1, numerical_features1, categorical_features1, LabelPropagation(), param_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________ Dataset:heart\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "If no scoring is specified, the estimator passed should have a 'score' method. The estimator <ipynb.fs.full.SemiBoost.SemiBoostClassifier object at 0x0000024BBA9F1460> does not.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-fb4e3972cdeb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m }\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mParameterTuning\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfilename3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf3r0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf3t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumerical_features3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_features3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSemiBoostClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mParameterTuning\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfilename2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf2r0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf2t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumerical_features2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_features2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSemiBoostClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mParameterTuning\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfilename1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf1r0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf1t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumerical_features1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_features1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSemiBoostClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-a33e6f7faf47>\u001b[0m in \u001b[0;36mParameterTuning\u001b[1;34m(dataset_name, dfr, dft, target, numerical_features, categorical_features, model, grid_params)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mmod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mresults_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXr_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myr_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults_r\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    751\u001b[0m             \u001b[0mscorers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscoring\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m             \u001b[0mscorers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m             \u001b[0mscorers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_multimetric_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    448\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m             raise TypeError(\n\u001b[0m\u001b[0;32m    451\u001b[0m                 \u001b[1;34m\"If no scoring is specified, the estimator passed should \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m                 \u001b[1;34m\"have a 'score' method. The estimator %r does not.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: If no scoring is specified, the estimator passed should have a 'score' method. The estimator <ipynb.fs.full.SemiBoost.SemiBoostClassifier object at 0x0000024BBA9F1460> does not."
     ]
    }
   ],
   "source": [
    "# SemiBoost\n",
    "\n",
    "param_grid = {\n",
    "    'similarity_kernel': ['knn','rbf'],\n",
    "    'n_neighbors': [3,4,5,6,7],\n",
    "    'max_models': [5,10,15,20],\n",
    "    'sample_percent': [0.25, 0.5, 0.75],\n",
    "    'sigma_percentile': [90, 95, 99]\n",
    "}\n",
    "\n",
    "ParameterTuning (filename3, df3r0, df3t, target3, numerical_features3, categorical_features3, SemiBoostClassifier(), param_grid)\n",
    "ParameterTuning (filename2, df2r0, df2t, target2, numerical_features2, categorical_features2, SemiBoostClassifier(), param_grid)\n",
    "ParameterTuning (filename1, df1r0, df1t, target1, numerical_features1, categorical_features1, SemiBoostClassifier(), param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
