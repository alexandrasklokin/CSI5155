{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System:\n",
      "    python: 3.8.5 (tags/v3.8.5:580fbb0, Jul 20 2020, 15:57:54) [MSC v.1924 64 bit (AMD64)]\n",
      "executable: c:\\users\\alexa\\appdata\\local\\programs\\python\\python38\\python.exe\n",
      "   machine: Windows-10-10.0.19041-SP0\n",
      "\n",
      "Python dependencies:\n",
      "          pip: 21.3.1\n",
      "   setuptools: 47.1.0\n",
      "      sklearn: 0.24.1\n",
      "        numpy: 1.19.2\n",
      "        scipy: 1.5.2\n",
      "       Cython: 0.29.22\n",
      "       pandas: 1.1.3\n",
      "   matplotlib: 3.3.2\n",
      "       joblib: 0.17.0\n",
      "threadpoolctl: 2.1.0\n",
      "\n",
      "Built with OpenMP: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "sklearn.show_versions()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = 'online_shoppers_intentions'\n",
    "\n",
    "df1r0 = pd.read_csv(\"../data/train/noresampling/\"+filename1+\"_0.csv\", index_col=0)\n",
    "df1u0 = pd.read_csv(\"../data/train/undersampled/\"+filename1+\"_0.csv\", index_col=0)\n",
    "df1o0 = pd.read_csv(\"../data/train/oversampled/\"+filename1+\"_0.csv\", index_col=0)\n",
    "\n",
    "df1r10 = pd.read_csv(\"../data/train/noresampling/\"+filename1+\"_10.csv\", index_col=0)\n",
    "df1u10 = pd.read_csv(\"../data/train/undersampled/\"+filename1+\"_10.csv\", index_col=0)\n",
    "df1o10 = pd.read_csv(\"../data/train/oversampled/\"+filename1+\"_10.csv\", index_col=0)\n",
    "\n",
    "df1r20 = pd.read_csv(\"../data/train/noresampling/\"+filename1+\"_20.csv\", index_col=0)\n",
    "df1u20 = pd.read_csv(\"../data/train/undersampled/\"+filename1+\"_20.csv\", index_col=0)\n",
    "df1o20 = pd.read_csv(\"../data/train/oversampled/\"+filename1+\"_20.csv\", index_col=0)\n",
    "\n",
    "df1r50 = pd.read_csv(\"../data/train/noresampling/\"+filename1+\"_50.csv\", index_col=0)\n",
    "df1u50 = pd.read_csv(\"../data/train/undersampled/\"+filename1+\"_50.csv\", index_col=0)\n",
    "df1o50 = pd.read_csv(\"../data/train/oversampled/\"+filename1+\"_50.csv\", index_col=0)\n",
    "\n",
    "df1r90 = pd.read_csv(\"../data/train/noresampling/\"+filename1+\"_90.csv\", index_col=0)\n",
    "df1u90 = pd.read_csv(\"../data/train/undersampled/\"+filename1+\"_90.csv\", index_col=0)\n",
    "df1o90 = pd.read_csv(\"../data/train/oversampled/\"+filename1+\"_90.csv\", index_col=0)\n",
    "\n",
    "df1r95 = pd.read_csv(\"../data/train/noresampling/\"+filename1+\"_95.csv\", index_col=0)\n",
    "df1u95 = pd.read_csv(\"../data/train/undersampled/\"+filename1+\"_95.csv\", index_col=0)\n",
    "df1o95 = pd.read_csv(\"../data/train/oversampled/\"+filename1+\"_95.csv\", index_col=0)\n",
    "\n",
    "df1t = pd.read_csv(\"../data/test/\"+filename1+\".csv\", index_col=0)\n",
    "\n",
    "numerical_features1 = [\"Administrative\", \"Administrative_Duration\", \"Informational\", \"Informational_Duration\", \n",
    "                      \"ProductRelated\", \"ProductRelated_Duration\", \"BounceRates\", \"ExitRates\", \"PageValues\", \"SpecialDay\"]\n",
    "categorical_features1 = [\"OperatingSystems\", \"Browser\", \"Region\", \"TrafficType\", \"VisitorType\", \"Weekend\", \"Month\"]\n",
    "target1 = 'Revenue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2 = 'marketing_campaign'\n",
    "\n",
    "df2r0 = pd.read_csv(\"../data/train/noresampling/\"+filename2+\"_0.csv\", index_col=0)\n",
    "df2u0 = pd.read_csv(\"../data/train/undersampled/\"+filename2+\"_0.csv\", index_col=0)\n",
    "df2o0 = pd.read_csv(\"../data/train/oversampled/\"+filename2+\"_0.csv\", index_col=0)\n",
    "\n",
    "df2r10 = pd.read_csv(\"../data/train/noresampling/\"+filename2+\"_10.csv\", index_col=0)\n",
    "df2u10 = pd.read_csv(\"../data/train/undersampled/\"+filename2+\"_10.csv\", index_col=0)\n",
    "df2o10 = pd.read_csv(\"../data/train/oversampled/\"+filename2+\"_10.csv\", index_col=0)\n",
    "\n",
    "df2r20 = pd.read_csv(\"../data/train/noresampling/\"+filename2+\"_20.csv\", index_col=0)\n",
    "df2u20 = pd.read_csv(\"../data/train/undersampled/\"+filename2+\"_20.csv\", index_col=0)\n",
    "df2o20 = pd.read_csv(\"../data/train/oversampled/\"+filename2+\"_20.csv\", index_col=0)\n",
    "\n",
    "df2r50 = pd.read_csv(\"../data/train/noresampling/\"+filename2+\"_50.csv\", index_col=0)\n",
    "df2u50 = pd.read_csv(\"../data/train/undersampled/\"+filename2+\"_50.csv\", index_col=0)\n",
    "df2o50 = pd.read_csv(\"../data/train/oversampled/\"+filename2+\"_50.csv\", index_col=0)\n",
    "\n",
    "df2r90 = pd.read_csv(\"../data/train/noresampling/\"+filename2+\"_90.csv\", index_col=0)\n",
    "df2u90 = pd.read_csv(\"../data/train/undersampled/\"+filename2+\"_90.csv\", index_col=0)\n",
    "df2o90 = pd.read_csv(\"../data/train/oversampled/\"+filename2+\"_90.csv\", index_col=0)\n",
    "\n",
    "df2r95 = pd.read_csv(\"../data/train/noresampling/\"+filename2+\"_95.csv\", index_col=0)\n",
    "df2u95 = pd.read_csv(\"../data/train/undersampled/\"+filename2+\"_95.csv\", index_col=0)\n",
    "df2o95 = pd.read_csv(\"../data/train/oversampled/\"+filename2+\"_95.csv\", index_col=0)\n",
    "\n",
    "df2t = pd.read_csv(\"../data/test/\"+filename2+\".csv\", index_col=0)\n",
    "\n",
    "numerical_features2 = ['Income','MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts','MntSweetProducts', \n",
    "                        'MntGoldProds','Year_Birth','Recency','NumDealsPurchases','NumWebPurchases',\n",
    "                        'NumCatalogPurchases','NumStorePurchases','NumWebVisitsMonth','Dt_Customer']\n",
    "categorical_features2 = ['Education','Marital_Status','Kidhome','AcceptedCmp3', \n",
    "                        'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2','Complain','Response']\n",
    "target2 = 'Teenhome'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename3 = 'heart'\n",
    "\n",
    "df3r0 = pd.read_csv(\"../data/train/noresampling/\"+filename3+\"_0.csv\", index_col=0)\n",
    "df3u0 = pd.read_csv(\"../data/train/undersampled/\"+filename3+\"_0.csv\", index_col=0)\n",
    "df3o0 = pd.read_csv(\"../data/train/oversampled/\"+filename3+\"_0.csv\", index_col=0)\n",
    "\n",
    "df3r10 = pd.read_csv(\"../data/train/noresampling/\"+filename3+\"_10.csv\", index_col=0)\n",
    "df3u10 = pd.read_csv(\"../data/train/undersampled/\"+filename3+\"_10.csv\", index_col=0)\n",
    "df3o10 = pd.read_csv(\"../data/train/oversampled/\"+filename3+\"_10.csv\", index_col=0)\n",
    "\n",
    "df3r20 = pd.read_csv(\"../data/train/noresampling/\"+filename3+\"_20.csv\", index_col=0)\n",
    "df3u20 = pd.read_csv(\"../data/train/undersampled/\"+filename3+\"_20.csv\", index_col=0)\n",
    "df3o20 = pd.read_csv(\"../data/train/oversampled/\"+filename3+\"_20.csv\", index_col=0)\n",
    "\n",
    "df3r50 = pd.read_csv(\"../data/train/noresampling/\"+filename3+\"_50.csv\", index_col=0)\n",
    "df3u50 = pd.read_csv(\"../data/train/undersampled/\"+filename3+\"_50.csv\", index_col=0)\n",
    "df3o50 = pd.read_csv(\"../data/train/oversampled/\"+filename3+\"_50.csv\", index_col=0)\n",
    "\n",
    "df3r90 = pd.read_csv(\"../data/train/noresampling/\"+filename3+\"_90.csv\", index_col=0)\n",
    "df3u90 = pd.read_csv(\"../data/train/undersampled/\"+filename3+\"_90.csv\", index_col=0)\n",
    "df3o90 = pd.read_csv(\"../data/train/oversampled/\"+filename3+\"_90.csv\", index_col=0)\n",
    "\n",
    "df3r95 = pd.read_csv(\"../data/train/noresampling/\"+filename3+\"_95.csv\", index_col=0)\n",
    "df3u95 = pd.read_csv(\"../data/train/undersampled/\"+filename3+\"_95.csv\", index_col=0)\n",
    "df3o95 = pd.read_csv(\"../data/train/oversampled/\"+filename3+\"_95.csv\", index_col=0)\n",
    "\n",
    "df3t = pd.read_csv(\"../data/test/\"+filename3+\".csv\", index_col=0)\n",
    "\n",
    "numerical_features3 = ['trestbps','chol','thalach','oldpeak', 'age']\n",
    "categorical_features3 = ['sex', 'cp','fbs','restecg','exang','slope','ca','thal']\n",
    "\n",
    "target3 = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 1514\n",
      "0.9499478623566214 8631\n",
      "0.2 14590\n",
      "0.8962264150943396 212\n",
      "0.09973579920739763 1514\n",
      "0.9484536082474226 194\n",
      "0.0 91\n"
     ]
    }
   ],
   "source": [
    "# SANITY CHECKS\n",
    "print(df2u50[target2].isnull().sum()/len(df2u50), len(df2u50))\n",
    "print(df1r95[target1].isnull().sum()/len(df1r95), len(df1r95))\n",
    "print(df1o20[target1].isnull().sum()/len(df1o20), len(df1o20))\n",
    "print(df3r90[target3].isnull().sum()/len(df3r90), len(df3r90))\n",
    "print(df2u10[target2].isnull().sum()/len(df2u10), len(df2u10))\n",
    "print(df3u95[target3].isnull().sum()/len(df3u95), len(df3u95))\n",
    "print(df3t[target3].isnull().sum()/len(df3t), len(df3t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Label_Prop_1(dftrain, dftest, categorical_features, numerical_features, target, model):\n",
    "        \n",
    "    start_time = time.time()\n",
    "    \n",
    "    X_train = dftrain[numerical_features+categorical_features]\n",
    "    y_train = dftrain[target]\n",
    "    pseudo = y_train.fillna(-1)\n",
    "    \n",
    "    X_test = dftest[numerical_features+categorical_features]\n",
    "    y_test = dftest[target]\n",
    "    \n",
    "    #print(pseudo.to_list())\n",
    "    \n",
    "    X_train[categorical_features] = X_train[categorical_features].astype('category')\n",
    "    X_test[categorical_features] = X_test[categorical_features].astype('category')\n",
    "    \n",
    "    model.fit(X_train, pseudo)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_prob = model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    rounded = []\n",
    "    for elem in y_pred_prob:\n",
    "        rounded.append(round(elem,10))\n",
    "    \n",
    "    execution = time.time() - start_time\n",
    "    \n",
    "    return [execution, y_pred, rounded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Label_Prop_All(dftrains, dftest, categorical_features, numerical_features, target, model, sampling, filename):\n",
    "    \n",
    "    y_test = dftest[target]\n",
    "    \n",
    "    results0 = Label_Prop_1(dftrains[0], dftest, categorical_features, numerical_features, target, model)\n",
    "    print('DONE: '+sampling+\"-\"+filename+'-0')\n",
    "    print(\"F1-Score: \"+str(f1_score(y_test, results0[1],average='weighted')))\n",
    "    results10 = Label_Prop_1(dftrains[1], dftest, categorical_features, numerical_features, target, model)\n",
    "    print('DONE: '+sampling+\"-\"+filename+'-10')\n",
    "    print(\"F1-Score: \"+str(f1_score(y_test, results10[1],average='weighted')))\n",
    "    results20 = Label_Prop_1(dftrains[2], dftest, categorical_features, numerical_features, target, model)\n",
    "    print('DONE: '+sampling+\"-\"+filename+'-20')\n",
    "    print(\"F1-Score: \"+str(f1_score(y_test, results20[1],average='weighted')))\n",
    "    results50 = Label_Prop_1(dftrains[3], dftest, categorical_features, numerical_features, target, model)\n",
    "    print('DONE: '+sampling+\"-\"+filename+'-50')\n",
    "    print(\"F1-Score: \"+str(f1_score(y_test, results50[1],average='weighted')))\n",
    "    results90 = Label_Prop_1(dftrains[4], dftest, categorical_features, numerical_features, target, model)\n",
    "    print('DONE: '+sampling+\"-\"+filename+'-90')\n",
    "    print(\"F1-Score: \"+str(f1_score(y_test, results90[1],average='weighted')))\n",
    "    results95 = Label_Prop_1(dftrains[5], dftest, categorical_features, numerical_features, target, model)\n",
    "    print('DONE: '+sampling+\"-\"+filename+'-95')\n",
    "    print(\"F1-Score: \"+str(f1_score(y_test, results95[1],average='weighted')))\n",
    "    \n",
    "    executions = [results0[0],results10[0],results20[0],results50[0],results90[0],results95[0]] \n",
    "    unlabelled = ['0','10','20','50','90','95']\n",
    "    \n",
    "    predictions_data = {'y_true':y_test, 'y_0':results0[1], 'y_10':results10[1], 'y_20':results20[1], \n",
    "                        'y_50':results50[1], 'y_90':results90[1], 'y_95':results95[1], 'y_0_prob':results0[2],\n",
    "                       'y_10_prob':results10[2], 'y_20_prob':results20[2],'y_50_prob':results50[2],\n",
    "                       'y_90_prob':results90[2], 'y_95_prob':results95[2]}\n",
    "    prediction_df = pd.DataFrame(predictions_data)\n",
    "    prediction_df.to_csv('../pred/labelpropagation/'+sampling+'/'+filename+'.csv')\n",
    "    \n",
    "    time_data = {'unlabelled':unlabelled,'time':executions}\n",
    "    time_df = pd.DataFrame(time_data)\n",
    "    time_df.to_csv('../pred/labelpropagation/'+sampling+'/'+filename+'_time.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: noresampling-online_shoppers_intentions-0\n",
      "F1-Score: 0.7745244693987265\n",
      "DONE: noresampling-online_shoppers_intentions-10\n",
      "F1-Score: 0.7745244693987265\n",
      "DONE: noresampling-online_shoppers_intentions-20\n",
      "F1-Score: 0.7745244693987265\n",
      "DONE: noresampling-online_shoppers_intentions-50\n",
      "F1-Score: 0.7745244693987265\n",
      "DONE: noresampling-online_shoppers_intentions-90\n",
      "F1-Score: 0.7745244693987265\n",
      "DONE: noresampling-online_shoppers_intentions-95\n",
      "F1-Score: 0.7745244693987265\n",
      "DONE: undersampled-online_shoppers_intentions-0\n",
      "F1-Score: 0.7745244693987265\n",
      "DONE: undersampled-online_shoppers_intentions-10\n",
      "F1-Score: 0.04141981459042541\n",
      "DONE: undersampled-online_shoppers_intentions-20\n",
      "F1-Score: 0.04141981459042541\n",
      "DONE: undersampled-online_shoppers_intentions-50\n",
      "F1-Score: 0.04141981459042541\n",
      "DONE: undersampled-online_shoppers_intentions-90\n",
      "F1-Score: 0.04141981459042541\n",
      "DONE: undersampled-online_shoppers_intentions-95\n",
      "F1-Score: 0.04141981459042541\n",
      "DONE: oversampled-online_shoppers_intentions-0\n",
      "F1-Score: 0.6990186115502207\n",
      "DONE: oversampled-online_shoppers_intentions-10\n",
      "F1-Score: 0.053251699100270694\n",
      "DONE: oversampled-online_shoppers_intentions-20\n",
      "F1-Score: 0.04141981459042541\n",
      "DONE: oversampled-online_shoppers_intentions-50\n",
      "F1-Score: 0.04141981459042541\n",
      "DONE: oversampled-online_shoppers_intentions-90\n",
      "F1-Score: 0.04141981459042541\n",
      "DONE: oversampled-online_shoppers_intentions-95\n",
      "F1-Score: 0.04141981459042541\n"
     ]
    }
   ],
   "source": [
    "# Best Supervised Model and Hyperparameters found in notebooks 1., 2., and 3. of tuning folder.\n",
    "\n",
    "# ONLINE SHOPPING INTENTION\n",
    "lb_1= LabelPropagation(kernel='knn',n_neighbors=2672) \n",
    "#Although I performed Hyperparameter tuning, I needed to user 500-nn, or else\n",
    "# predict_prob would return nan for many of the dataframes\n",
    "\n",
    "noresampling = [df1r0,df1r10,df1r20,df1r50,df1r90,df1r95]\n",
    "undersampling = [df1u0,df1u10,df1u20,df1u50,df1u90,df1u95]\n",
    "oversampling = [df1o0,df1o10,df1o20,df1o50,df1o90,df1o95]\n",
    "\n",
    "Label_Prop_All(noresampling, df1t, categorical_features1, numerical_features1, target1, lb_1, 'noresampling', filename1)\n",
    "Label_Prop_All(undersampling, df1t, categorical_features1, numerical_features1, target1, lb_1, 'undersampled', filename1)\n",
    "Label_Prop_All(oversampling, df1t, categorical_features1, numerical_features1, target1, lb_1, 'oversampled', filename1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: noresampling-marketing_campaign-0\n",
      "F1-Score: 0.745378471619078\n",
      "DONE: noresampling-marketing_campaign-10\n",
      "F1-Score: 0.4459446243332047\n",
      "DONE: noresampling-marketing_campaign-20\n",
      "F1-Score: 0.40005940484854685\n",
      "DONE: noresampling-marketing_campaign-50\n",
      "F1-Score: 0.5668722165125043\n",
      "DONE: noresampling-marketing_campaign-90\n",
      "F1-Score: 0.31530603715909633\n",
      "DONE: noresampling-marketing_campaign-95\n",
      "F1-Score: 0.36538257373979066\n",
      "DONE: undersampled-marketing_campaign-0\n",
      "F1-Score: 0.7494274162782492\n",
      "DONE: undersampled-marketing_campaign-10\n",
      "F1-Score: 0.5089800212928769\n",
      "DONE: undersampled-marketing_campaign-20\n",
      "F1-Score: 0.49567628597738383\n",
      "DONE: undersampled-marketing_campaign-50\n",
      "F1-Score: 0.3146514629948365\n",
      "DONE: undersampled-marketing_campaign-90\n",
      "F1-Score: 0.31530603715909633\n",
      "DONE: undersampled-marketing_campaign-95\n",
      "F1-Score: 0.31530603715909633\n",
      "DONE: oversampled-marketing_campaign-0\n",
      "F1-Score: 0.7479959205850131\n",
      "DONE: oversampled-marketing_campaign-10\n",
      "F1-Score: 0.424468374134213\n",
      "DONE: oversampled-marketing_campaign-20\n",
      "F1-Score: 0.44280787258975185\n",
      "DONE: oversampled-marketing_campaign-50\n",
      "F1-Score: 0.4503578554504481\n",
      "DONE: oversampled-marketing_campaign-90\n",
      "F1-Score: 0.31530603715909633\n",
      "DONE: oversampled-marketing_campaign-95\n",
      "F1-Score: 0.31530603715909633\n"
     ]
    }
   ],
   "source": [
    "# MARKETING CAMPAIGN\n",
    "lb_2= LabelPropagation(kernel='knn',n_neighbors=500) \n",
    "#Although I performed Hyperparameter tuning, I needed to user 500-nn, or else\n",
    "# predict_prob would return nan for many of the dataframes\n",
    " \n",
    "noresampling = [df2r0,df2r10,df2r20,df2r50,df2r90,df2r95]\n",
    "undersampling = [df2u0,df2u10,df2u20,df2u50,df2u90,df2u95]\n",
    "oversampling = [df2o0,df2o10,df2o20,df2o50,df2o90,df2o95]\n",
    "\n",
    "Label_Prop_All(noresampling, df2t, categorical_features2, numerical_features2, target2, lb_2, 'noresampling', filename2)\n",
    "Label_Prop_All(undersampling, df2t, categorical_features2, numerical_features2, target2, lb_2, 'undersampled', filename2)\n",
    "Label_Prop_All(oversampling, df2t, categorical_features2, numerical_features2, target2, lb_2, 'oversampled', filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: noresampling-heart-0\n",
      "F1-Score: 0.6050684009867683\n",
      "DONE: noresampling-heart-10\n",
      "F1-Score: 0.40803092256580625\n",
      "DONE: noresampling-heart-20\n",
      "F1-Score: 0.5812917474682181\n",
      "DONE: noresampling-heart-50\n",
      "F1-Score: 0.5784924322823515\n",
      "DONE: noresampling-heart-90\n",
      "F1-Score: 0.5777524362430022\n",
      "DONE: noresampling-heart-95\n",
      "F1-Score: 0.6444231042046334\n",
      "DONE: undersampled-heart-0\n",
      "F1-Score: 0.44050838614086163\n",
      "DONE: undersampled-heart-10\n",
      "F1-Score: 0.5274725274725273\n",
      "DONE: undersampled-heart-20\n",
      "F1-Score: 0.41687050267908354\n",
      "DONE: undersampled-heart-50\n",
      "F1-Score: 0.5101398537335438\n",
      "DONE: undersampled-heart-90\n",
      "F1-Score: 0.38461538461538464\n",
      "DONE: undersampled-heart-95\n",
      "F1-Score: 0.5645540267389006\n",
      "DONE: oversampled-heart-0\n",
      "F1-Score: 0.5392464678178963\n",
      "DONE: oversampled-heart-10\n",
      "F1-Score: 0.5364529087933343\n",
      "DONE: oversampled-heart-20\n",
      "F1-Score: 0.5695324707245563\n",
      "DONE: oversampled-heart-50\n",
      "F1-Score: 0.3793977340488969\n",
      "DONE: oversampled-heart-90\n",
      "F1-Score: 0.47367526090930345\n",
      "DONE: oversampled-heart-95\n",
      "F1-Score: 0.47367526090930345\n"
     ]
    }
   ],
   "source": [
    "# HEART\n",
    "lb_3= LabelPropagation(kernel='rbf') \n",
    "# max_iter=10,n_neighbors=3,tol=0.0001,gamma=40\n",
    "\n",
    "noresampling = [df3r0,df3r10,df3r20,df3r50,df3r90,df3r95]\n",
    "undersampling = [df3u0,df3u10,df3u20,df3u50,df3u90,df3u95]\n",
    "oversampling = [df3o0,df3o10,df3o20,df3o50,df3o90,df3o95]\n",
    "\n",
    "Label_Prop_All(noresampling, df3t, categorical_features3, numerical_features3, target3, lb_3, 'noresampling', filename3)\n",
    "Label_Prop_All(undersampling, df3t, categorical_features3, numerical_features3, target3, lb_3, 'undersampled', filename3)\n",
    "Label_Prop_All(oversampling, df3t, categorical_features3, numerical_features3, target3, lb_3, 'oversampled', filename3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.639873,\n",
       " 0.632184,\n",
       " 0.64277,\n",
       " 0.647513,\n",
       " 0.641432,\n",
       " 0.642258,\n",
       " 0.641102,\n",
       " 0.633989,\n",
       " 0.645288,\n",
       " 0.645446,\n",
       " 0.639032,\n",
       " 0.644915,\n",
       " 0.645864,\n",
       " 0.641908,\n",
       " 0.637379,\n",
       " 0.641856,\n",
       " 0.637987,\n",
       " 0.640926,\n",
       " 0.641891,\n",
       " 0.633649,\n",
       " 0.63112,\n",
       " 0.642823,\n",
       " 0.646875,\n",
       " 0.628419,\n",
       " 0.63348,\n",
       " 0.643932,\n",
       " 0.639581,\n",
       " 0.642888,\n",
       " 0.645027,\n",
       " 0.648306,\n",
       " 0.64112,\n",
       " 0.635483,\n",
       " 0.643231,\n",
       " 0.632483,\n",
       " 0.643165,\n",
       " 0.636103,\n",
       " 0.632561,\n",
       " 0.644693,\n",
       " 0.634174,\n",
       " 0.64658,\n",
       " 0.634055,\n",
       " 0.644531,\n",
       " 0.63545,\n",
       " 0.630234,\n",
       " 0.630602,\n",
       " 0.635534,\n",
       " 0.642455,\n",
       " 0.648076,\n",
       " 0.643303,\n",
       " 0.641638,\n",
       " 0.630931,\n",
       " 0.639538,\n",
       " 0.646809,\n",
       " 0.642499,\n",
       " 0.642608,\n",
       " 0.637657,\n",
       " 0.645131,\n",
       " 0.631644,\n",
       " 0.634181,\n",
       " 0.642824,\n",
       " 0.634299,\n",
       " 0.653208,\n",
       " 0.646423,\n",
       " 0.645298,\n",
       " 0.644969,\n",
       " 0.642924,\n",
       " 0.641361,\n",
       " 0.63766,\n",
       " 0.644892,\n",
       " 0.641114,\n",
       " 0.644251,\n",
       " 0.636433,\n",
       " 0.634378,\n",
       " 0.632642,\n",
       " 0.640717,\n",
       " 0.636428,\n",
       " 0.647001,\n",
       " 0.645014,\n",
       " 0.644415,\n",
       " 0.645342,\n",
       " 0.644242,\n",
       " 0.632922,\n",
       " 0.636578,\n",
       " 0.627857,\n",
       " 0.631773,\n",
       " 0.643269,\n",
       " 0.643647,\n",
       " 0.648719,\n",
       " 0.651006,\n",
       " 0.645601,\n",
       " 0.641383,\n",
       " 0.630978,\n",
       " 0.639559,\n",
       " 0.638669,\n",
       " 0.637032,\n",
       " 0.643599,\n",
       " 0.64784,\n",
       " 0.641858,\n",
       " 0.63694,\n",
       " 0.644455,\n",
       " 0.636736,\n",
       " 0.643623,\n",
       " 0.630546,\n",
       " 0.64605,\n",
       " 0.638509,\n",
       " 0.641683,\n",
       " 0.631315,\n",
       " 0.644008,\n",
       " 0.64586,\n",
       " 0.647849,\n",
       " 0.643251,\n",
       " 0.644367,\n",
       " 0.632617,\n",
       " 0.644732,\n",
       " 0.635843,\n",
       " 0.643381,\n",
       " 0.646774,\n",
       " 0.647012,\n",
       " 0.632593,\n",
       " 0.645681,\n",
       " 0.63641,\n",
       " 0.631093,\n",
       " 0.642629,\n",
       " 0.645076,\n",
       " 0.646016,\n",
       " 0.647254,\n",
       " 0.638689,\n",
       " 0.642125,\n",
       " 0.644164,\n",
       " 0.64258,\n",
       " 0.633776,\n",
       " 0.631504,\n",
       " 0.634364,\n",
       " 0.634286,\n",
       " 0.643089,\n",
       " 0.642327,\n",
       " 0.649577,\n",
       " 0.643061,\n",
       " 0.634497,\n",
       " 0.634284,\n",
       " 0.633777,\n",
       " 0.643005,\n",
       " 0.631839,\n",
       " 0.634027,\n",
       " 0.644044,\n",
       " 0.638867,\n",
       " 0.641727,\n",
       " 0.632477,\n",
       " 0.647832,\n",
       " 0.641053,\n",
       " 0.64492,\n",
       " 0.644544,\n",
       " 0.642649,\n",
       " 0.640616,\n",
       " 0.642026,\n",
       " 0.642928,\n",
       " 0.63028,\n",
       " 0.643732,\n",
       " 0.634789,\n",
       " 0.648394,\n",
       " 0.633264,\n",
       " 0.634936,\n",
       " 0.644157,\n",
       " 0.64489,\n",
       " 0.639075,\n",
       " 0.638225,\n",
       " 0.645758,\n",
       " 0.641003,\n",
       " 0.64014,\n",
       " 0.643603,\n",
       " 0.635222,\n",
       " 0.633762,\n",
       " 0.647868,\n",
       " 0.639829,\n",
       " 0.648851,\n",
       " 0.646625,\n",
       " 0.644931,\n",
       " 0.641098,\n",
       " 0.646045,\n",
       " 0.641432,\n",
       " 0.642599,\n",
       " 0.643363,\n",
       " 0.631645,\n",
       " 0.645079,\n",
       " 0.640137,\n",
       " 0.64267,\n",
       " 0.634235,\n",
       " 0.640808,\n",
       " 0.644586,\n",
       " 0.642446,\n",
       " 0.646039,\n",
       " 0.645183,\n",
       " 0.648582,\n",
       " 0.646267,\n",
       " 0.644585,\n",
       " 0.63491,\n",
       " 0.632351,\n",
       " 0.633672,\n",
       " 0.640997,\n",
       " 0.635889,\n",
       " 0.630764,\n",
       " 0.645004,\n",
       " 0.632782,\n",
       " 0.63136,\n",
       " 0.646116,\n",
       " 0.642203,\n",
       " 0.633896,\n",
       " 0.642677,\n",
       " 0.645979,\n",
       " 0.644275,\n",
       " 0.645021,\n",
       " 0.636241,\n",
       " 0.64414,\n",
       " 0.63777,\n",
       " 0.635303,\n",
       " 0.634107,\n",
       " 0.64212,\n",
       " 0.641283,\n",
       " 0.639006,\n",
       " 0.636077,\n",
       " 0.645681,\n",
       " 0.638152,\n",
       " 0.641388,\n",
       " 0.63004,\n",
       " 0.64224,\n",
       " 0.63586,\n",
       " 0.636376,\n",
       " 0.648768,\n",
       " 0.636813,\n",
       " 0.637219,\n",
       " 0.646527,\n",
       " 0.642741,\n",
       " 0.635903,\n",
       " 0.643267,\n",
       " 0.645769,\n",
       " 0.643476,\n",
       " 0.645019,\n",
       " 0.634783,\n",
       " 0.643594,\n",
       " 0.644765,\n",
       " 0.634343,\n",
       " 0.645544,\n",
       " 0.645192,\n",
       " 0.638432,\n",
       " 0.645969,\n",
       " 0.642217,\n",
       " 0.637216,\n",
       " 0.643336,\n",
       " 0.640864,\n",
       " 0.637421,\n",
       " 0.64445,\n",
       " 0.642833,\n",
       " 0.635967,\n",
       " 0.633311,\n",
       " 0.647392,\n",
       " 0.640104,\n",
       " 0.641582,\n",
       " 0.642305,\n",
       " 0.63286,\n",
       " 0.640999,\n",
       " 0.62992,\n",
       " 0.640244,\n",
       " 0.643566,\n",
       " 0.645957,\n",
       " 0.631506,\n",
       " 0.643222,\n",
       " 0.633902,\n",
       " 0.644613,\n",
       " 0.644696,\n",
       " 0.629232,\n",
       " 0.631296,\n",
       " 0.64354,\n",
       " 0.634341,\n",
       " 0.633439,\n",
       " 0.636811,\n",
       " 0.634609,\n",
       " 0.632005,\n",
       " 0.644774,\n",
       " 0.651554,\n",
       " 0.631567,\n",
       " 0.643217,\n",
       " 0.634734,\n",
       " 0.639804,\n",
       " 0.648715,\n",
       " 0.635804,\n",
       " 0.645373,\n",
       " 0.630915,\n",
       " 0.634075,\n",
       " 0.643709,\n",
       " 0.636611,\n",
       " 0.648276,\n",
       " 0.641731,\n",
       " 0.634492,\n",
       " 0.636957,\n",
       " 0.641793,\n",
       " 0.646646,\n",
       " 0.628402,\n",
       " 0.64502,\n",
       " 0.636424,\n",
       " 0.633354,\n",
       " 0.644712,\n",
       " 0.645568,\n",
       " 0.646612,\n",
       " 0.634214,\n",
       " 0.641755,\n",
       " 0.644404,\n",
       " 0.630811,\n",
       " 0.647118,\n",
       " 0.641948,\n",
       " 0.644538,\n",
       " 0.643507,\n",
       " 0.633249,\n",
       " 0.648903,\n",
       " 0.635483,\n",
       " 0.638311,\n",
       " 0.649081,\n",
       " 0.638172,\n",
       " 0.634725,\n",
       " 0.645118,\n",
       " 0.638606,\n",
       " 0.646576,\n",
       " 0.635501,\n",
       " 0.638528,\n",
       " 0.633721,\n",
       " 0.637037,\n",
       " 0.643585,\n",
       " 0.633083,\n",
       " 0.637955,\n",
       " 0.642032,\n",
       " 0.637945,\n",
       " 0.632866,\n",
       " 0.648603,\n",
       " 0.642386,\n",
       " 0.643936,\n",
       " 0.640048,\n",
       " 0.649,\n",
       " 0.644125,\n",
       " 0.632845,\n",
       " 0.64058,\n",
       " 0.64503,\n",
       " 0.642472,\n",
       " 0.642104,\n",
       " 0.636428,\n",
       " 0.641903,\n",
       " 0.641259,\n",
       " 0.631098,\n",
       " 0.646801,\n",
       " 0.64151,\n",
       " 0.646273,\n",
       " 0.642969,\n",
       " 0.646564,\n",
       " 0.634296,\n",
       " 0.643386,\n",
       " 0.644907,\n",
       " 0.638052,\n",
       " 0.636368,\n",
       " 0.641945,\n",
       " 0.636321,\n",
       " 0.644189,\n",
       " 0.638674,\n",
       " 0.639858,\n",
       " 0.64255,\n",
       " 0.637626,\n",
       " 0.648079,\n",
       " 0.643496,\n",
       " 0.63357,\n",
       " 0.635221,\n",
       " 0.633883,\n",
       " 0.641208,\n",
       " 0.640256,\n",
       " 0.637878,\n",
       " 0.636175,\n",
       " 0.644376,\n",
       " 0.639976,\n",
       " 0.643564,\n",
       " 0.632762,\n",
       " 0.637032,\n",
       " 0.645336,\n",
       " 0.645162,\n",
       " 0.633571,\n",
       " 0.636667,\n",
       " 0.644331,\n",
       " 0.643901,\n",
       " 0.632951,\n",
       " 0.63261,\n",
       " 0.633535,\n",
       " 0.644367,\n",
       " 0.646307,\n",
       " 0.648367,\n",
       " 0.651074,\n",
       " 0.633063,\n",
       " 0.642509,\n",
       " 0.634611,\n",
       " 0.641762,\n",
       " 0.631103,\n",
       " 0.637646,\n",
       " 0.644603,\n",
       " 0.632734,\n",
       " 0.631813,\n",
       " 0.629451,\n",
       " 0.641148,\n",
       " 0.646772,\n",
       " 0.64231,\n",
       " 0.644592,\n",
       " 0.633366,\n",
       " 0.63532,\n",
       " 0.640779,\n",
       " 0.635977,\n",
       " 0.638652,\n",
       " 0.645467,\n",
       " 0.637981,\n",
       " 0.640289,\n",
       " 0.643634,\n",
       " 0.643798,\n",
       " 0.643402,\n",
       " 0.646738,\n",
       " 0.629662,\n",
       " 0.64937,\n",
       " 0.645381,\n",
       " 0.63418,\n",
       " 0.637243,\n",
       " 0.645779,\n",
       " 0.633752,\n",
       " 0.64746,\n",
       " 0.63641,\n",
       " 0.647546,\n",
       " 0.646343,\n",
       " 0.646576,\n",
       " 0.646968,\n",
       " 0.642086,\n",
       " 0.64576,\n",
       " 0.637177,\n",
       " 0.632819,\n",
       " 0.640413,\n",
       " 0.646298,\n",
       " 0.64004,\n",
       " 0.642241,\n",
       " 0.642113,\n",
       " 0.637606,\n",
       " 0.648715,\n",
       " 0.64388,\n",
       " 0.639303,\n",
       " 0.628855,\n",
       " 0.642912,\n",
       " 0.646242,\n",
       " 0.631103,\n",
       " 0.646909,\n",
       " 0.631855,\n",
       " 0.645993,\n",
       " 0.636578,\n",
       " 0.640511,\n",
       " 0.645888,\n",
       " 0.643676,\n",
       " 0.633495,\n",
       " 0.646841,\n",
       " 0.63212,\n",
       " 0.63741,\n",
       " 0.650074,\n",
       " 0.637826,\n",
       " 0.642897,\n",
       " 0.63634,\n",
       " 0.638297,\n",
       " 0.645575,\n",
       " 0.645147,\n",
       " 0.641554,\n",
       " 0.649071,\n",
       " 0.64046,\n",
       " 0.645614,\n",
       " 0.633058,\n",
       " 0.643726,\n",
       " 0.635461,\n",
       " 0.632381,\n",
       " 0.645118,\n",
       " 0.639959,\n",
       " 0.642987,\n",
       " 0.643709,\n",
       " 0.641451,\n",
       " 0.646483,\n",
       " 0.642904,\n",
       " 0.636021,\n",
       " 0.644426,\n",
       " 0.633182,\n",
       " 0.636115,\n",
       " 0.640196,\n",
       " 0.645144,\n",
       " 0.644625,\n",
       " 0.635473,\n",
       " 0.645494,\n",
       " 0.642302,\n",
       " 0.643066,\n",
       " 0.633896,\n",
       " 0.644701,\n",
       " 0.645374,\n",
       " 0.636378,\n",
       " 0.631712,\n",
       " 0.634186,\n",
       " 0.637557,\n",
       " 0.642937,\n",
       " 0.647324,\n",
       " 0.646448,\n",
       " 0.638819,\n",
       " 0.64568,\n",
       " 0.633002,\n",
       " 0.648133,\n",
       " 0.641441,\n",
       " 0.64424,\n",
       " 0.636101,\n",
       " 0.642037,\n",
       " 0.634519,\n",
       " 0.636381,\n",
       " 0.650559,\n",
       " 0.645547,\n",
       " 0.640942,\n",
       " 0.634818,\n",
       " 0.630677,\n",
       " 0.637609,\n",
       " 0.636556,\n",
       " 0.636111,\n",
       " 0.632257,\n",
       " 0.646435,\n",
       " 0.628107,\n",
       " 0.642715,\n",
       " 0.645186,\n",
       " 0.644577,\n",
       " 0.632406,\n",
       " 0.630802,\n",
       " 0.637207,\n",
       " 0.643211,\n",
       " 0.643574,\n",
       " 0.643381,\n",
       " 0.644799,\n",
       " 0.636004,\n",
       " 0.635991,\n",
       " 0.632682,\n",
       " 0.633978,\n",
       " 0.634894,\n",
       " 0.644208,\n",
       " 0.645568,\n",
       " 0.642888,\n",
       " 0.63644,\n",
       " 0.632561,\n",
       " 0.640104,\n",
       " 0.640524,\n",
       " 0.64475,\n",
       " 0.640193,\n",
       " 0.632237,\n",
       " 0.643566,\n",
       " 0.648473,\n",
       " 0.638303,\n",
       " 0.644013,\n",
       " 0.632958,\n",
       " 0.641598,\n",
       " 0.641465,\n",
       " 0.634018,\n",
       " 0.641754,\n",
       " 0.645169,\n",
       " 0.644421,\n",
       " 0.645065,\n",
       " 0.642457,\n",
       " 0.649368,\n",
       " 0.628465,\n",
       " 0.642705,\n",
       " 0.634881,\n",
       " 0.639456,\n",
       " 0.632911,\n",
       " 0.645963,\n",
       " 0.629907,\n",
       " 0.634306,\n",
       " 0.644054,\n",
       " 0.641361,\n",
       " 0.645191,\n",
       " 0.644381,\n",
       " 0.634587,\n",
       " 0.643661,\n",
       " 0.638638,\n",
       " 0.642213,\n",
       " 0.635723,\n",
       " 0.642734,\n",
       " 0.641392,\n",
       " 0.635432,\n",
       " 0.637785,\n",
       " 0.641955,\n",
       " 0.636801,\n",
       " 0.629852,\n",
       " 0.643956,\n",
       " 0.644359,\n",
       " 0.640986,\n",
       " 0.645568,\n",
       " 0.644136,\n",
       " 0.632956,\n",
       " 0.644635,\n",
       " 0.644952,\n",
       " 0.638674,\n",
       " 0.644303,\n",
       " 0.64537,\n",
       " 0.631963,\n",
       " 0.643137,\n",
       " 0.635162,\n",
       " 0.632388,\n",
       " 0.629983,\n",
       " 0.641575,\n",
       " 0.643102,\n",
       " 0.64789,\n",
       " 0.628859,\n",
       " 0.635576,\n",
       " 0.634528,\n",
       " 0.645852,\n",
       " 0.645601,\n",
       " 0.641306,\n",
       " 0.629683,\n",
       " 0.634729,\n",
       " 0.631902,\n",
       " 0.646194,\n",
       " 0.64449,\n",
       " 0.633058,\n",
       " 0.646112,\n",
       " 0.633676,\n",
       " 0.644283,\n",
       " 0.644318,\n",
       " 0.634497,\n",
       " 0.631642,\n",
       " 0.643735,\n",
       " 0.639969,\n",
       " 0.644836,\n",
       " 0.635529,\n",
       " 0.633684,\n",
       " 0.64548,\n",
       " 0.632835,\n",
       " 0.644753,\n",
       " 0.646351,\n",
       " 0.645857,\n",
       " 0.643504,\n",
       " 0.642876,\n",
       " 0.643531,\n",
       " 0.644438,\n",
       " 0.644319,\n",
       " 0.644849,\n",
       " 0.626977,\n",
       " 0.64246,\n",
       " 0.645241,\n",
       " 0.642914,\n",
       " 0.642391,\n",
       " 0.643496,\n",
       " 0.635802,\n",
       " 0.63932,\n",
       " 0.635745,\n",
       " 0.632078,\n",
       " 0.646209,\n",
       " 0.639388,\n",
       " 0.636174,\n",
       " 0.645572,\n",
       " 0.643446,\n",
       " 0.645233,\n",
       " 0.643009,\n",
       " 0.639666,\n",
       " 0.641751,\n",
       " 0.636252,\n",
       " 0.64231,\n",
       " 0.641949,\n",
       " 0.644586,\n",
       " 0.64706,\n",
       " 0.631656,\n",
       " 0.634478,\n",
       " 0.64066,\n",
       " 0.642956,\n",
       " 0.637197,\n",
       " 0.645364,\n",
       " 0.635352,\n",
       " 0.641016,\n",
       " 0.637216,\n",
       " 0.634587,\n",
       " 0.643305]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Check\n",
    "[t, p, pp] = Label_Prop_1(df2u95, df2t, categorical_features2, numerical_features2, target2, lb_2)\n",
    "\n",
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
