{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from numpy import asarray\n",
    "from statistics import mean\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import set_printoptions\n",
    "from statistics import mean\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLINE SHOPPING INTENTIONS\n",
    "\n",
    "filename1 = 'online_shoppers_intentions'\n",
    "df1r0 = pd.read_csv(\"../data/train/noresampling/\"+filename1+\"_0.csv\", index_col=0)\n",
    "df1t = pd.read_csv(\"../data/test/\"+filename1+\".csv\", index_col=0)\n",
    "target1 = 'Revenue'\n",
    "\n",
    "numerical_features1 = [\"Administrative\", \"Administrative_Duration\", \"Informational\", \"Informational_Duration\", \n",
    "                      \"ProductRelated\", \"ProductRelated_Duration\", \"BounceRates\", \"ExitRates\", \"PageValues\", \"SpecialDay\"]\n",
    "categorical_features1 = [\"OperatingSystems\", \"Browser\", \"Region\", \"TrafficType\", \"VisitorType\", \"Weekend\", \"Month\"]\n",
    "df1r0[categorical_features1] = df1r0[categorical_features1].astype('category')  \n",
    "df1t[categorical_features1] = df1t[categorical_features1].astype('category')\n",
    "df1r0[target1] = df1r0[target1].astype('category') \n",
    "df1t[target1] = df1t[target1].astype('category')\n",
    "\n",
    "\n",
    "# MARKETING CAMPAIGN\n",
    "\n",
    "filename2 = 'marketing_campaign'\n",
    "df2r0 = pd.read_csv(\"../data/train/noresampling/\"+filename2+\"_0.csv\", index_col=0)\n",
    "df2t = pd.read_csv(\"../data/test/\"+filename2+\".csv\", index_col=0)\n",
    "target2 = 'Teenhome'\n",
    "\n",
    "numerical_features2 = ['Income','MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts','MntSweetProducts', \n",
    "                        'MntGoldProds','Year_Birth','Recency','NumDealsPurchases','NumWebPurchases',\n",
    "                        'NumCatalogPurchases','NumStorePurchases','NumWebVisitsMonth','Dt_Customer']\n",
    "categorical_features2 = ['Education','Marital_Status','Kidhome','AcceptedCmp3', \n",
    "                        'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2','Complain','Response']\n",
    "df2r0[categorical_features2] = df2r0[categorical_features2].astype('category') \n",
    "df2t[categorical_features2] = df2t[categorical_features2].astype('category')\n",
    "df2r0[target2] = df2r0[target2].astype('category') \n",
    "df2t[target2] = df2t[target2].astype('category')\n",
    "\n",
    "# HEART\n",
    "\n",
    "filename3 = 'heart'\n",
    "df3r0 = pd.read_csv(\"../data/train/noresampling/\"+filename3+\"_0.csv\", index_col=0)\n",
    "df3t = pd.read_csv(\"../data/test/\"+filename3+\".csv\", index_col=0)\n",
    "target3 = 'target'\n",
    "\n",
    "numerical_features3 = ['trestbps','chol','thalach','oldpeak', 'age']\n",
    "categorical_features3 = ['sex', 'cp','fbs','restecg','exang','slope','ca','thal']\n",
    "df3r0[categorical_features3] = df3r0[categorical_features3].astype('category') \n",
    "df3t[categorical_features3] = df3t[categorical_features3].astype('category') \n",
    "df3r0[target3] = df3r0[target3].astype('category') \n",
    "df3t[target3] = df3t[target3].astype('category')\n",
    "\n",
    "# Sanity Check\n",
    "#df1r0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ParameterTuning (dataset_name, dfr, dft, target, numerical_features, categorical_features, model, grid_params):\n",
    "    \n",
    "    print(\"_______________________________________________________________________________ Dataset:\"+dataset_name)\n",
    "\n",
    "    Xr_train = dfr[numerical_features+categorical_features]\n",
    "    yr_train = dfr[target]\n",
    "    \n",
    "    X_test = dft[numerical_features+categorical_features]\n",
    "    y_test = dft[target]\n",
    "\n",
    "    mod = GridSearchCV(model, grid_params, verbose=1, cv=3, n_jobs=-1)\n",
    "    results_r = mod.fit(Xr_train, yr_train)\n",
    "    print(results_r.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________ Dataset:heart\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "{'max_depth': 5, 'max_features': 2, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "_______________________________________________________________________________ Dataset:marketing_campaign\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "{'max_depth': 15, 'max_features': 5, 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 200}\n",
      "_______________________________________________________________________________ Dataset:online_shoppers_intentions\n",
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    }
   ],
   "source": [
    "# RF\n",
    "param_grid_rf = {\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'max_features': [2, 3, 4, 5],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10],\n",
    "    'n_estimators': [100, 200]\n",
    "}\n",
    "ParameterTuning (filename3, df3r0, df3t, target3, numerical_features3, categorical_features3, RandomForestClassifier(), param_grid_rf)\n",
    "ParameterTuning (filename2, df2r0, df2t, target2, numerical_features2, categorical_features2, RandomForestClassifier(), param_grid_rf)\n",
    "ParameterTuning (filename1, df1r0, df1t, target1, numerical_features1, categorical_features1, RandomForestClassifier(), param_grid_rf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBE\n",
    "param_grad_gbe = {\n",
    "    \"n_estimators\":[5,50,250],\n",
    "    \"max_depth\":[1,3,5,7],\n",
    "    \"learning_rate\":[0.01,0.1,1]\n",
    "}\n",
    "\n",
    "ParameterTuning (filename3, df3r0, df3t, target3, numerical_features3, categorical_features3, GradientBoostingClassifier(), param_grad_gbe)\n",
    "ParameterTuning (filename2, df2r0, df2t, target2, numerical_features2, categorical_features2, GradientBoostingClassifier(), param_grad_gbe)\n",
    "ParameterTuning (filename1, df1r0, df1t, target1, numerical_features1, categorical_features1, GradientBoostingClassifier(), param_grad_gbe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT\n",
    "param_grad_dt = { 'criterion' : ['gini', 'entropy'],\n",
    "               'max_depth':range(1,10), \"min_samples_split\":range(1,10),\n",
    "              'min_samples_leaf':range(1,5)}\n",
    "\n",
    "ParameterTuning (filename3, df3r0, df3t, target3, numerical_features3, categorical_features3, DecisionTreeClassifier(), param_grad_dt)\n",
    "ParameterTuning (filename2, df2r0, df2t, target2, numerical_features2, categorical_features2, DecisionTreeClassifier(), param_grad_dt)\n",
    "ParameterTuning (filename1, df1r0, df1t, target1, numerical_features1, categorical_features1, DecisionTreeClassifier(), param_grad_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
