{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System:\n",
      "    python: 3.8.5 (tags/v3.8.5:580fbb0, Jul 20 2020, 15:57:54) [MSC v.1924 64 bit (AMD64)]\n",
      "executable: c:\\users\\alexa\\appdata\\local\\programs\\python\\python38\\python.exe\n",
      "   machine: Windows-10-10.0.19041-SP0\n",
      "\n",
      "Python dependencies:\n",
      "          pip: 21.3.1\n",
      "   setuptools: 47.1.0\n",
      "      sklearn: 0.24.1\n",
      "        numpy: 1.19.2\n",
      "        scipy: 1.5.2\n",
      "       Cython: 0.29.22\n",
      "       pandas: 1.1.3\n",
      "   matplotlib: 3.3.2\n",
      "       joblib: 0.17.0\n",
      "threadpoolctl: 2.1.0\n",
      "\n",
      "Built with OpenMP: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "sklearn.show_versions()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = 'online_shoppers_intentions'\n",
    "\n",
    "df1r0 = pd.read_csv(\"../data/train/noresampling/\"+filename1+\"_0.csv\", index_col=0)\n",
    "df1u0 = pd.read_csv(\"../data/train/undersampled/\"+filename1+\"_0.csv\", index_col=0)\n",
    "df1o0 = pd.read_csv(\"../data/train/oversampled/\"+filename1+\"_0.csv\", index_col=0)\n",
    "\n",
    "df1r10 = pd.read_csv(\"../data/train/noresampling/\"+filename1+\"_10.csv\", index_col=0)\n",
    "df1u10 = pd.read_csv(\"../data/train/undersampled/\"+filename1+\"_10.csv\", index_col=0)\n",
    "df1o10 = pd.read_csv(\"../data/train/oversampled/\"+filename1+\"_10.csv\", index_col=0)\n",
    "\n",
    "df1r20 = pd.read_csv(\"../data/train/noresampling/\"+filename1+\"_20.csv\", index_col=0)\n",
    "df1u20 = pd.read_csv(\"../data/train/undersampled/\"+filename1+\"_20.csv\", index_col=0)\n",
    "df1o20 = pd.read_csv(\"../data/train/oversampled/\"+filename1+\"_20.csv\", index_col=0)\n",
    "\n",
    "df1r50 = pd.read_csv(\"../data/train/noresampling/\"+filename1+\"_50.csv\", index_col=0)\n",
    "df1u50 = pd.read_csv(\"../data/train/undersampled/\"+filename1+\"_50.csv\", index_col=0)\n",
    "df1o50 = pd.read_csv(\"../data/train/oversampled/\"+filename1+\"_50.csv\", index_col=0)\n",
    "\n",
    "df1r90 = pd.read_csv(\"../data/train/noresampling/\"+filename1+\"_90.csv\", index_col=0)\n",
    "df1u90 = pd.read_csv(\"../data/train/undersampled/\"+filename1+\"_90.csv\", index_col=0)\n",
    "df1o90 = pd.read_csv(\"../data/train/oversampled/\"+filename1+\"_90.csv\", index_col=0)\n",
    "\n",
    "df1r95 = pd.read_csv(\"../data/train/noresampling/\"+filename1+\"_95.csv\", index_col=0)\n",
    "df1u95 = pd.read_csv(\"../data/train/undersampled/\"+filename1+\"_95.csv\", index_col=0)\n",
    "df1o95 = pd.read_csv(\"../data/train/oversampled/\"+filename1+\"_95.csv\", index_col=0)\n",
    "\n",
    "df1t = pd.read_csv(\"../data/test/\"+filename1+\".csv\", index_col=0)\n",
    "\n",
    "numerical_features1 = [\"Administrative\", \"Administrative_Duration\", \"Informational\", \"Informational_Duration\", \n",
    "                      \"ProductRelated\", \"ProductRelated_Duration\", \"BounceRates\", \"ExitRates\", \"PageValues\", \"SpecialDay\"]\n",
    "categorical_features1 = [\"OperatingSystems\", \"Browser\", \"Region\", \"TrafficType\", \"VisitorType\", \"Weekend\", \"Month\"]\n",
    "target1 = 'Revenue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2 = 'marketing_campaign'\n",
    "\n",
    "df2r0 = pd.read_csv(\"../data/train/noresampling/\"+filename2+\"_0.csv\", index_col=0)\n",
    "df2u0 = pd.read_csv(\"../data/train/undersampled/\"+filename2+\"_0.csv\", index_col=0)\n",
    "df2o0 = pd.read_csv(\"../data/train/oversampled/\"+filename2+\"_0.csv\", index_col=0)\n",
    "\n",
    "df2r10 = pd.read_csv(\"../data/train/noresampling/\"+filename2+\"_10.csv\", index_col=0)\n",
    "df2u10 = pd.read_csv(\"../data/train/undersampled/\"+filename2+\"_10.csv\", index_col=0)\n",
    "df2o10 = pd.read_csv(\"../data/train/oversampled/\"+filename2+\"_10.csv\", index_col=0)\n",
    "\n",
    "df2r20 = pd.read_csv(\"../data/train/noresampling/\"+filename2+\"_20.csv\", index_col=0)\n",
    "df2u20 = pd.read_csv(\"../data/train/undersampled/\"+filename2+\"_20.csv\", index_col=0)\n",
    "df2o20 = pd.read_csv(\"../data/train/oversampled/\"+filename2+\"_20.csv\", index_col=0)\n",
    "\n",
    "df2r50 = pd.read_csv(\"../data/train/noresampling/\"+filename2+\"_50.csv\", index_col=0)\n",
    "df2u50 = pd.read_csv(\"../data/train/undersampled/\"+filename2+\"_50.csv\", index_col=0)\n",
    "df2o50 = pd.read_csv(\"../data/train/oversampled/\"+filename2+\"_50.csv\", index_col=0)\n",
    "\n",
    "df2r90 = pd.read_csv(\"../data/train/noresampling/\"+filename2+\"_90.csv\", index_col=0)\n",
    "df2u90 = pd.read_csv(\"../data/train/undersampled/\"+filename2+\"_90.csv\", index_col=0)\n",
    "df2o90 = pd.read_csv(\"../data/train/oversampled/\"+filename2+\"_90.csv\", index_col=0)\n",
    "\n",
    "df2r95 = pd.read_csv(\"../data/train/noresampling/\"+filename2+\"_95.csv\", index_col=0)\n",
    "df2u95 = pd.read_csv(\"../data/train/undersampled/\"+filename2+\"_95.csv\", index_col=0)\n",
    "df2o95 = pd.read_csv(\"../data/train/oversampled/\"+filename2+\"_95.csv\", index_col=0)\n",
    "\n",
    "df2t = pd.read_csv(\"../data/test/\"+filename2+\".csv\", index_col=0)\n",
    "\n",
    "numerical_features2 = ['Income','MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts','MntSweetProducts', \n",
    "                        'MntGoldProds','Year_Birth','Recency','NumDealsPurchases','NumWebPurchases',\n",
    "                        'NumCatalogPurchases','NumStorePurchases','NumWebVisitsMonth','Dt_Customer']\n",
    "categorical_features2 = ['Education','Marital_Status','Kidhome','AcceptedCmp3', \n",
    "                        'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2','Complain','Response']\n",
    "target2 = 'Teenhome'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename3 = 'heart'\n",
    "\n",
    "df3r0 = pd.read_csv(\"../data/train/noresampling/\"+filename3+\"_0.csv\", index_col=0)\n",
    "df3u0 = pd.read_csv(\"../data/train/undersampled/\"+filename3+\"_0.csv\", index_col=0)\n",
    "df3o0 = pd.read_csv(\"../data/train/oversampled/\"+filename3+\"_0.csv\", index_col=0)\n",
    "\n",
    "df3r10 = pd.read_csv(\"../data/train/noresampling/\"+filename3+\"_10.csv\", index_col=0)\n",
    "df3u10 = pd.read_csv(\"../data/train/undersampled/\"+filename3+\"_10.csv\", index_col=0)\n",
    "df3o10 = pd.read_csv(\"../data/train/oversampled/\"+filename3+\"_10.csv\", index_col=0)\n",
    "\n",
    "df3r20 = pd.read_csv(\"../data/train/noresampling/\"+filename3+\"_20.csv\", index_col=0)\n",
    "df3u20 = pd.read_csv(\"../data/train/undersampled/\"+filename3+\"_20.csv\", index_col=0)\n",
    "df3o20 = pd.read_csv(\"../data/train/oversampled/\"+filename3+\"_20.csv\", index_col=0)\n",
    "\n",
    "df3r50 = pd.read_csv(\"../data/train/noresampling/\"+filename3+\"_50.csv\", index_col=0)\n",
    "df3u50 = pd.read_csv(\"../data/train/undersampled/\"+filename3+\"_50.csv\", index_col=0)\n",
    "df3o50 = pd.read_csv(\"../data/train/oversampled/\"+filename3+\"_50.csv\", index_col=0)\n",
    "\n",
    "df3r90 = pd.read_csv(\"../data/train/noresampling/\"+filename3+\"_90.csv\", index_col=0)\n",
    "df3u90 = pd.read_csv(\"../data/train/undersampled/\"+filename3+\"_90.csv\", index_col=0)\n",
    "df3o90 = pd.read_csv(\"../data/train/oversampled/\"+filename3+\"_90.csv\", index_col=0)\n",
    "\n",
    "df3r95 = pd.read_csv(\"../data/train/noresampling/\"+filename3+\"_95.csv\", index_col=0)\n",
    "df3u95 = pd.read_csv(\"../data/train/undersampled/\"+filename3+\"_95.csv\", index_col=0)\n",
    "df3o95 = pd.read_csv(\"../data/train/oversampled/\"+filename3+\"_95.csv\", index_col=0)\n",
    "\n",
    "df3t = pd.read_csv(\"../data/test/\"+filename3+\".csv\", index_col=0)\n",
    "\n",
    "numerical_features3 = ['trestbps','chol','thalach','oldpeak', 'age']\n",
    "categorical_features3 = ['sex', 'cp','fbs','restecg','exang','slope','ca','thal']\n",
    "target3 = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 1514\n",
      "0.9499478623566214 8631\n",
      "0.2 14590\n",
      "0.8962264150943396 212\n",
      "0.09973579920739763 1514\n",
      "0.0 91\n"
     ]
    }
   ],
   "source": [
    "# SANITY CHECKS\n",
    "print(df2u50[target2].isnull().sum()/len(df2u50), len(df2u50))\n",
    "print(df1r95[target1].isnull().sum()/len(df1r95), len(df1r95))\n",
    "print(df1o20[target1].isnull().sum()/len(df1o20), len(df1o20))\n",
    "print(df3r90[target3].isnull().sum()/len(df3r90), len(df3r90))\n",
    "print(df2u10[target2].isnull().sum()/len(df2u10), len(df2u10))\n",
    "print(df3t[target3].isnull().sum()/len(df3t), len(df3t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Self_Train_1(dftrain, dftest, categorical_features, numerical_features, target, model):\n",
    "        \n",
    "    start_time = time.time()\n",
    "    \n",
    "    X_train = dftrain[numerical_features+categorical_features]\n",
    "    y_train = dftrain[target]\n",
    "    pseudo = y_train.fillna(-1)\n",
    "    \n",
    "    X_test = dftest[numerical_features+categorical_features]\n",
    "    y_test = dftest[target]\n",
    "    \n",
    "    X_train[categorical_features] = X_train[categorical_features].astype('category')\n",
    "    X_test[categorical_features] = X_test[categorical_features].astype('category')\n",
    "    \n",
    "    m = SelfTrainingClassifier(model)\n",
    "    m.fit(X_train, pseudo)\n",
    "    y_pred = m.predict(X_test)\n",
    "    \n",
    "    execution = time.time() - start_time\n",
    "    \n",
    "    return [execution, y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Self_Train_All(dftrains, dftest, categorical_features, numerical_features, target, model, sampling, filename):\n",
    "    \n",
    "    y_test = dftest[target]\n",
    "    \n",
    "    results0 = Self_Train_1(dftrains[0], dftest, categorical_features, numerical_features, target, model)\n",
    "    print('DONE: '+sampling+\"-\"+filename+'-0')\n",
    "    results10 = Self_Train_1(dftrains[1], dftest, categorical_features, numerical_features, target, model)\n",
    "    print('DONE: '+sampling+\"-\"+filename+'-10')\n",
    "    results20 = Self_Train_1(dftrains[2], dftest, categorical_features, numerical_features, target, model)\n",
    "    print('DONE: '+sampling+\"-\"+filename+'-20')\n",
    "    results50 = Self_Train_1(dftrains[3], dftest, categorical_features, numerical_features, target, model)\n",
    "    print('DONE: '+sampling+\"-\"+filename+'-50')\n",
    "    results90 = Self_Train_1(dftrains[4], dftest, categorical_features, numerical_features, target, model)\n",
    "    print('DONE: '+sampling+\"-\"+filename+'-90')\n",
    "    results95 = Self_Train_1(dftrains[5], dftest, categorical_features, numerical_features, target, model)\n",
    "    print('DONE: '+sampling+\"-\"+filename+'-95')\n",
    "    \n",
    "    executions = [results0[0],results10[0],results20[0],results50[0],results90[0],results95[0]] \n",
    "    unlabelled = ['0','10','20','50','90','95']\n",
    "    \n",
    "    predictions_data = {'y_true':y_test, 'y_0':results0[1], 'y_10':results10[1], 'y_20':results20[1], \n",
    "                        'y_50':results50[1], 'y_90':results90[1], 'y_95':results95[1]}\n",
    "    prediction_df = pd.DataFrame(predictions_data)\n",
    "    prediction_df.to_csv('../data/pred/selftraining/'+sampling+'/'+filename+'.csv')\n",
    "    \n",
    "    time_data = {'unlabelled':unlabelled,'time':executions}\n",
    "    time_df = pd.DataFrame(time_data)\n",
    "    time_df.to_csv('../data/pred/selftraining/'+sampling+'/'+filename+'_time.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: noresampling-online_shoppers_intentions-0\n",
      "DONE: noresampling-online_shoppers_intentions-10\n",
      "DONE: noresampling-online_shoppers_intentions-20\n",
      "DONE: noresampling-online_shoppers_intentions-50\n",
      "DONE: noresampling-online_shoppers_intentions-90\n",
      "DONE: noresampling-online_shoppers_intentions-95\n",
      "DONE: undersampled-online_shoppers_intentions-0\n",
      "DONE: undersampled-online_shoppers_intentions-10\n",
      "DONE: undersampled-online_shoppers_intentions-20\n",
      "DONE: undersampled-online_shoppers_intentions-50\n",
      "DONE: undersampled-online_shoppers_intentions-90\n",
      "DONE: undersampled-online_shoppers_intentions-95\n",
      "DONE: oversampled-online_shoppers_intentions-0\n",
      "DONE: oversampled-online_shoppers_intentions-10\n",
      "DONE: oversampled-online_shoppers_intentions-20\n",
      "DONE: oversampled-online_shoppers_intentions-50\n",
      "DONE: oversampled-online_shoppers_intentions-90\n",
      "DONE: oversampled-online_shoppers_intentions-95\n"
     ]
    }
   ],
   "source": [
    "# Best Supervised Model and Hyperparameters found in notebooks 1. and 2.\n",
    "\n",
    "# ONLINE SHOPPING INTENTION\n",
    "gbe_1 = GradientBoostingClassifier(learning_rate=1, max_depth=1, n_estimators=5) #no-resampling\n",
    "rf_1 = RandomForestClassifier(max_depth=5, max_features=3, min_samples_leaf=3, min_samples_split=8, n_estimators=100)\n",
    "\n",
    "noresampling = [df1r0,df1r10,df1r20,df1r50,df1r90,df1r95]\n",
    "undersampling = [df1u0,df1u10,df1u20,df1u50,df1u90,df1u95]\n",
    "oversampling = [df1o0,df1o10,df1o20,df1o50,df1o90,df1o95]\n",
    "\n",
    "Self_Train_All(noresampling, df1t, categorical_features1, numerical_features1, target1, gbe_1, 'noresampling', filename1)\n",
    "Self_Train_All(undersampling, df1t, categorical_features1, numerical_features1, target1, rf_1, 'undersampled', filename1)\n",
    "Self_Train_All(oversampling, df1t, categorical_features1, numerical_features1, target1, rf_1, 'oversampled', filename1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: noresampling-marketing_campaign-0\n",
      "DONE: noresampling-marketing_campaign-10\n",
      "DONE: noresampling-marketing_campaign-20\n",
      "DONE: noresampling-marketing_campaign-50\n",
      "DONE: noresampling-marketing_campaign-90\n",
      "DONE: noresampling-marketing_campaign-95\n",
      "DONE: undersampled-marketing_campaign-0\n",
      "DONE: undersampled-marketing_campaign-10\n",
      "DONE: undersampled-marketing_campaign-20\n",
      "DONE: undersampled-marketing_campaign-50\n",
      "DONE: undersampled-marketing_campaign-90\n",
      "DONE: undersampled-marketing_campaign-95\n",
      "DONE: oversampled-marketing_campaign-0\n",
      "DONE: oversampled-marketing_campaign-10\n",
      "DONE: oversampled-marketing_campaign-20\n",
      "DONE: oversampled-marketing_campaign-50\n",
      "DONE: oversampled-marketing_campaign-90\n",
      "DONE: oversampled-marketing_campaign-95\n"
     ]
    }
   ],
   "source": [
    "# MARKETING CAMPAIGN\n",
    "gbe_2 = GradientBoostingClassifier(learning_rate=0.1, max_depth=3, n_estimators=250) #no-resampling\n",
    "rf_2 = RandomForestClassifier(max_depth=15, max_features=5, min_samples_leaf=3, min_samples_split=8, n_estimators=200)\n",
    "\n",
    "noresampling = [df2r0,df2r10,df2r20,df2r50,df2r90,df2r95]\n",
    "undersampling = [df2u0,df2u10,df2u20,df2u50,df2u90,df2u95]\n",
    "oversampling = [df2o0,df2o10,df2o20,df2o50,df2o90,df2o95]\n",
    "\n",
    "Self_Train_All(noresampling, df2t, categorical_features2, numerical_features2, target2, gbe_2, 'noresampling', filename2)\n",
    "Self_Train_All(undersampling, df2t, categorical_features2, numerical_features2, target2, rf_2, 'undersampled', filename2)\n",
    "Self_Train_All(oversampling, df2t, categorical_features2, numerical_features2, target2, rf_2, 'oversampled', filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: noresampling-heart-0\n",
      "DONE: noresampling-heart-10\n",
      "DONE: noresampling-heart-20\n",
      "DONE: noresampling-heart-50\n",
      "DONE: noresampling-heart-90\n",
      "DONE: noresampling-heart-95\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '../data/pred/selftraining/noresampling/heart.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-153-8f42f09f5521>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0moversampling\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdf3o0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf3o10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf3o20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf3o50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf3o90\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf3o95\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mSelf_Train_All\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoresampling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf3t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_features3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumerical_features3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt_3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'noresampling'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mSelf_Train_All\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mundersampling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf3t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_features3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumerical_features3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgbe_3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'undersampled'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mSelf_Train_All\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moversampling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf3t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_features3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumerical_features3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgbe_3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'oversampled'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-146-5a3e28b66abb>\u001b[0m in \u001b[0;36mSelf_Train_All\u001b[1;34m(dftrains, dftest, categorical_features, numerical_features, target, model, sampling, filename)\u001b[0m\n\u001b[0;32m     22\u001b[0m                         'y_50':results50[1], 'y_90':results90[1], 'y_95':results95[1]}\n\u001b[0;32m     23\u001b[0m     \u001b[0mprediction_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mprediction_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/pred/selftraining/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msampling\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mtime_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'unlabelled'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0munlabelled\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mexecutions\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[0;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3169\u001b[0m         )\n\u001b[1;32m-> 3170\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             f, handles = get_handle(\n\u001b[0m\u001b[0;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexa\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '../data/pred/selftraining/noresampling/heart.csv'"
     ]
    }
   ],
   "source": [
    "# HEART\n",
    "dt_3 = DecisionTreeClassifier(criterion='entropy', max_depth=2, min_samples_leaf=1, min_samples_split= 2) #no-resampling\n",
    "gbe_3 = GradientBoostingClassifier(learning_rate=1, max_depth=1, n_estimators=50)\n",
    "\n",
    "noresampling = [df3r0,df3r10,df3r20,df3r50,df3r90,df3r95]\n",
    "undersampling = [df3u0,df3u10,df3u20,df3u50,df3u90,df3u95]\n",
    "oversampling = [df3o0,df3o10,df3o20,df3o50,df3o90,df3o95]\n",
    "\n",
    "Self_Train_All(noresampling, df3t, categorical_features3, numerical_features3, target3, dt_3, 'noresampling', filename3)\n",
    "Self_Train_All(undersampling, df3t, categorical_features3, numerical_features3, target3, gbe_3, 'undersampled', filename3)\n",
    "Self_Train_All(oversampling, df3t, categorical_features3, numerical_features3, target3, gbe_3, 'oversampled', filename3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity checks\n",
    "\n",
    "results = Self_Train_1(df3r0, df3t, categorical_features3, numerical_features3, target3, dt_3)\n",
    "print(results[1])\n",
    "\n",
    "results = Self_Train_1(df3r95, df3t, categorical_features3, numerical_features3, target3, dt_3)\n",
    "print(results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
